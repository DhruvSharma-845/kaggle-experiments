{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nshakespeare_url = \"https://homl.info/shakespeare\"\n\nfile_path = keras.utils.get_file('shakespeare.txt', shakespeare_url)\n\nwith open(file_path) as f:\n    shakespeare_text = f.read()\n\nprint(shakespeare_text[:80])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:22:52.140578Z","iopub.execute_input":"2025-04-26T11:22:52.140819Z","iopub.status.idle":"2025-04-26T11:23:08.617424Z","shell.execute_reply.started":"2025-04-26T11:22:52.140794Z","shell.execute_reply":"2025-04-26T11:23:08.616836Z"}},"outputs":[{"name":"stderr","text":"2025-04-26 11:22:54.368557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745666574.700099      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745666574.783278      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://homl.info/shakespeare\n\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nFirst Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"text_vectorization = keras.layers.TextVectorization(split='character', standardize='lower')\ntext_vectorization.adapt([shakespeare_text])\nencoded = text_vectorization([shakespeare_text])[0]\nencoded -= 2\n\nn_tokens = text_vectorization.vocabulary_size() - 2 \nprint('Number of distinct tokens: {}'.format(n_tokens))\ndataset_size = len(encoded) \nprint('Number of total tokens: {}'.format(dataset_size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:29:22.543014Z","iopub.execute_input":"2025-04-26T11:29:22.543351Z","iopub.status.idle":"2025-04-26T11:29:24.464136Z","shell.execute_reply.started":"2025-04-26T11:29:22.543328Z","shell.execute_reply":"2025-04-26T11:29:24.463478Z"}},"outputs":[{"name":"stdout","text":"Number of distinct tokens: 39\nNumber of total tokens: 1115394\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n    ds = tf.data.Dataset.from_tensor_slices(sequence)\n    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n    ds = ds.batch(batch_size)\n    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:32:25.316355Z","iopub.execute_input":"2025-04-26T11:32:25.316982Z","iopub.status.idle":"2025-04-26T11:32:25.321691Z","shell.execute_reply.started":"2025-04-26T11:32:25.316959Z","shell.execute_reply":"2025-04-26T11:32:25.321125Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tf.random.set_seed(42)\n\ntrain_ds = to_dataset(encoded[:1000000], 128, True, 42)\nvalid_ds = to_dataset(encoded[1000000:1060000], 128, True, 42)\ntest_ds = to_dataset(encoded[1060000:], 128, True, 42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:37:05.192121Z","iopub.execute_input":"2025-04-26T11:37:05.192880Z","iopub.status.idle":"2025-04-26T11:37:05.674329Z","shell.execute_reply.started":"2025-04-26T11:37:05.192856Z","shell.execute_reply":"2025-04-26T11:37:05.673755Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"inputs = keras.layers.Input(shape=(None, ), dtype='int64')\nx = keras.layers.Embedding(input_dim = n_tokens, output_dim = 16)(inputs)\nx = keras.layers.GRU(128, return_sequences=True)(x)\noutputs = keras.layers.Dense(n_tokens, activation=\"softmax\")(x)\nmodel = keras.Model(inputs, outputs)\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\nmodel_ckpt = keras.callbacks.ModelCheckpoint(\"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True)\n\nhistory = model.fit(train_ds, validation_data=valid_ds, epochs=4, callbacks=[model_ckpt])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:44:51.773405Z","iopub.execute_input":"2025-04-26T11:44:51.773975Z","iopub.status.idle":"2025-04-26T12:03:38.208438Z","shell.execute_reply.started":"2025-04-26T11:44:51.773955Z","shell.execute_reply":"2025-04-26T12:03:38.207759Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/4\n  31243/Unknown \u001b[1m267s\u001b[0m 8ms/step - accuracy: 0.5546 - loss: 1.4748","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 8ms/step - accuracy: 0.5546 - loss: 1.4748 - val_accuracy: 0.5361 - val_loss: 1.5985\nEpoch 2/4\n\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 8ms/step - accuracy: 0.6023 - loss: 1.2798 - val_accuracy: 0.5434 - val_loss: 1.5650\nEpoch 3/4\n\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 8ms/step - accuracy: 0.6066 - loss: 1.2602 - val_accuracy: 0.5454 - val_loss: 1.5602\nEpoch 4/4\n\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 8ms/step - accuracy: 0.6089 - loss: 1.2498 - val_accuracy: 0.5476 - val_loss: 1.5618\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"encoded_predictions = text_vectorization(['To be or not to b'])[0]\nencoded_predictions -=2\n\nencoded_predictions = encoded_predictions[tf.newaxis, :]\nprint(encoded_predictions.shape)\n\npredictions = model.predict([encoded_predictions])\nprint(predictions.shape)\n\ny_pred = tf.argmax(predictions[0,-1])  # choose the most probable character ID\nprint('Next character is: {}'.format(text_vectorization.get_vocabulary()[y_pred + 2]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:14:19.763735Z","iopub.execute_input":"2025-04-26T12:14:19.763978Z","iopub.status.idle":"2025-04-26T12:14:19.837306Z","shell.execute_reply.started":"2025-04-26T12:14:19.763963Z","shell.execute_reply":"2025-04-26T12:14:19.836720Z"}},"outputs":[{"name":"stdout","text":"(1, 17)\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n(1, 17, 39)\nNext character is: e\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def next_char(text, temperature=1):\n    text_predictions = text_vectorization([text])[0]\n    text_predictions -=2\n    text_predictions = text_predictions[tf.newaxis, :]\n    \n    y_proba = model.predict([text_predictions])[0, -1:]\n    rescaled_logits = tf.math.log(y_proba) / temperature\n    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n    return text_vectorization.get_vocabulary()[char_id + 2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:19:07.428915Z","iopub.execute_input":"2025-04-26T12:19:07.429226Z","iopub.status.idle":"2025-04-26T12:19:07.433708Z","shell.execute_reply.started":"2025-04-26T12:19:07.429203Z","shell.execute_reply":"2025-04-26T12:19:07.433127Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def extend_text(text, n_chars=50, temperature=1):\n    for _ in range(n_chars):\n        text += next_char(text, temperature)\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:19:10.160729Z","iopub.execute_input":"2025-04-26T12:19:10.161317Z","iopub.status.idle":"2025-04-26T12:19:10.164727Z","shell.execute_reply.started":"2025-04-26T12:19:10.161296Z","shell.execute_reply":"2025-04-26T12:19:10.163981Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(extend_text(\"To be or not to be\", temperature=0.01))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:19:12.688004Z","iopub.execute_input":"2025-04-26T12:19:12.688539Z","iopub.status.idle":"2025-04-26T12:19:16.266902Z","shell.execute_reply.started":"2025-04-26T12:19:12.688519Z","shell.execute_reply":"2025-04-26T12:19:16.266334Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\nTo be or not to be the law in the strength come\nto see the duke and \n","output_type":"stream"}],"execution_count":30}]}