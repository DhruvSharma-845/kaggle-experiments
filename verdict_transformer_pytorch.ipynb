{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:35.811783Z","iopub.execute_input":"2025-05-25T05:47:35.812066Z","iopub.status.idle":"2025-05-25T05:47:36.071101Z","shell.execute_reply.started":"2025-05-25T05:47:35.812044Z","shell.execute_reply":"2025-05-25T05:47:36.070413Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n!tar -xf aclImdb_v1.tar.gz\n!rm -r aclImdb/train/unsup","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:36.072524Z","iopub.execute_input":"2025-05-25T05:47:36.073178Z","iopub.status.idle":"2025-05-25T05:47:44.353047Z","shell.execute_reply.started":"2025-05-25T05:47:36.073159Z","shell.execute_reply":"2025-05-25T05:47:44.352005Z"}},"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 80.2M  100 80.2M    0     0  34.2M      0  0:00:02  0:00:02 --:--:-- 34.2M\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:44.354155Z","iopub.execute_input":"2025-05-25T05:47:44.354506Z","iopub.status.idle":"2025-05-25T05:47:48.188929Z","shell.execute_reply.started":"2025-05-25T05:47:44.354474Z","shell.execute_reply":"2025-05-25T05:47:48.188232Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\ndataset_dir = '/kaggle/working/aclImdb'\ntraining_set_dir = os.path.join(dataset_dir, 'train')\nvalidation_set_dir = os.path.join(dataset_dir, 'valid')\ntest_set_dir = os.path.join(dataset_dir, 'test')\n\nos.makedirs(validation_set_dir, exist_ok=True) \n\nfor category in ['pos', 'neg']:\n    source_directory = os.path.join(training_set_dir, category)\n    destination_directory = os.path.join(validation_set_dir, category)\n    os.makedirs(destination_directory, exist_ok=True)\n    source_files = os.listdir(source_directory)\n    num_files_to_move = int(0.2 * len(source_files))\n    for i in range(1, num_files_to_move + 1):\n        os.rename(os.path.join(source_directory, source_files[i]), os.path.join(destination_directory, source_files[i]))\n\nprint('Number of files in training positive set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/train/pos'))))\nprint('Number of files in training negative set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/train/neg'))))\nprint('Number of files in validation positive set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/valid/pos'))))\nprint('Number of files in validation negative set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/valid/neg'))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:48.189857Z","iopub.execute_input":"2025-05-25T05:47:48.190153Z","iopub.status.idle":"2025-05-25T05:47:48.328075Z","shell.execute_reply.started":"2025-05-25T05:47:48.190117Z","shell.execute_reply":"2025-05-25T05:47:48.327383Z"}},"outputs":[{"name":"stdout","text":"Number of files in training positive set is 10000\nNumber of files in training negative set is 10000\nNumber of files in validation positive set is 2500\nNumber of files in validation negative set is 2500\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import urllib.request\nurl = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\")\nfile_path = \"the-verdict.txt\"\nurllib.request.urlretrieve(url, file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:48.330202Z","iopub.execute_input":"2025-05-25T05:47:48.330422Z","iopub.status.idle":"2025-05-25T05:47:48.540214Z","shell.execute_reply.started":"2025-05-25T05:47:48.330406Z","shell.execute_reply":"2025-05-25T05:47:48.539456Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('the-verdict.txt', <http.client.HTTPMessage at 0x7911735802d0>)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()\nprint(\"Total number of character:\", len(raw_text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:48.541123Z","iopub.execute_input":"2025-05-25T05:47:48.541375Z","iopub.status.idle":"2025-05-25T05:47:48.546148Z","shell.execute_reply.started":"2025-05-25T05:47:48.541357Z","shell.execute_reply":"2025-05-25T05:47:48.545285Z"}},"outputs":[{"name":"stdout","text":"Total number of character: 20479\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import tiktoken\ntokenizer = tiktoken.get_encoding(\"gpt2\")\nprint(tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:48.546902Z","iopub.execute_input":"2025-05-25T05:47:48.547251Z","iopub.status.idle":"2025-05-25T05:47:50.117091Z","shell.execute_reply.started":"2025-05-25T05:47:48.547222Z","shell.execute_reply":"2025-05-25T05:47:50.116336Z"}},"outputs":[{"name":"stdout","text":"<Encoding 'gpt2'>\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        token_ids = tokenizer.encode(txt)\n\n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i + 1: i + max_length + 1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:50.118169Z","iopub.execute_input":"2025-05-25T05:47:50.118377Z","iopub.status.idle":"2025-05-25T05:47:54.278375Z","shell.execute_reply.started":"2025-05-25T05:47:50.118360Z","shell.execute_reply":"2025-05-25T05:47:54.277722Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch.nn as nn\nclass SelfAttention_v1(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n        super().__init__()\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer(\n           'mask',\n           torch.triu(torch.ones(context_length, context_length), diagonal=1)\n        )\n\n    def forward(self, x):\n        b, num_tokens, emb_size = x\n        keys = x @ self.W_key\n        queries = x @ self.W_query\n        values = x @ self.W_value\n\n        attn_scores = queries @ keys.transpose(1, 2)\n        \n        # attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n\n        # context_length = attn_scores.shape[0]\n        # mask_simple = torch.tril(torch.ones(context_length, context_length))\n\n        # masked_weights = attn_weights * mask_simple\n        # row_sums = masked_weights.sum(dim=-1, keepdim=True)\n        # norm_masked_weights = masked_weights / row_sums\n\n        masked_weights = attn_scores.masked_fill(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n        norm_masked_weights = torch.softmax(masked_weights / keys.shape[-1]**0.5, dim=1)\n\n        norm_masked_weights = self.dropout(norm_masked_weights)\n        \n        context_vec = norm_masked_weights @ values\n        return context_vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:54.279211Z","iopub.execute_input":"2025-05-25T05:47:54.279859Z","iopub.status.idle":"2025-05-25T05:47:54.286182Z","shell.execute_reply.started":"2025-05-25T05:47:54.279833Z","shell.execute_reply":"2025-05-25T05:47:54.285403Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class MultiHeadAttentionWrapper(nn.Module):\n    def __init__(self, d_in, d_out, context_length,\n                 dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        self.heads = nn.ModuleList(\n            [SelfAttention_v1(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads)]\n        )\n\n    def forward(self, x):\n        return torch.cat([head(x) for head in self.heads], dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:54.286866Z","iopub.execute_input":"2025-05-25T05:47:54.287083Z","iopub.status.idle":"2025-05-25T05:47:54.306072Z","shell.execute_reply.started":"2025-05-25T05:47:54.287060Z","shell.execute_reply":"2025-05-25T05:47:54.305450Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n       \n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads \n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        \n        self.out_proj = nn.Linear(d_out, d_out) \n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer(\n            \"mask\",\n            torch.triu(torch.ones(context_length, context_length),diagonal=1)\n        )\n\n    def forward(self, x):\n        b, num_tokens, d_in = x.shape\n        keys = self.W_key(x) \n        queries = self.W_query(x)\n        values = self.W_value(x)\n\n        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n        values = values.view(b, num_tokens, self.num_heads, self.head_dim)  \n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)                                                                   \n\n        keys = keys.transpose(1, 2)\n        queries = queries.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        attn_scores = queries @ keys.transpose(2, 3)\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n\n        attn_scores.masked_fill_(mask_bool, -torch.inf)\n\n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        context_vec = (attn_weights @ values).transpose(1, 2)\n        \n        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec)\n        return context_vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:54.306910Z","iopub.execute_input":"2025-05-25T05:47:54.307217Z","iopub.status.idle":"2025-05-25T05:47:54.320586Z","shell.execute_reply.started":"2025-05-25T05:47:54.307200Z","shell.execute_reply":"2025-05-25T05:47:54.319915Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"GPT_CONFIG_124M = {\n    \"vocab_size\": 50257,     # Vocabulary size\n    \"context_length\": 256,   # Context length; 1024 in GPT\n    \"emb_dim\": 768,          # Embedding dimension\n    \"n_heads\": 12,           # Number of attention heads\n    \"n_layers\": 12,          # Number of layers\n    \"drop_rate\": 0.1,        # Dropout rate\n    \"qkv_bias\": False        # Query-Key-Value bias\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:54.321262Z","iopub.execute_input":"2025-05-25T05:47:54.321445Z","iopub.status.idle":"2025-05-25T05:47:54.337385Z","shell.execute_reply.started":"2025-05-25T05:47:54.321430Z","shell.execute_reply":"2025-05-25T05:47:54.336638Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\n\nclass LayerNorm(nn.Module):  \n    def __init__(self, emb_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(emb_dim))\n        self.shift = nn.Parameter(torch.zeros(emb_dim))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n        return self.scale * norm_x + self.shift\n\nclass GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n            (x + 0.044715 * torch.pow(x, 3))\n        ))\n        \nclass FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n            GELU(),\n            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.att = MultiHeadAttention(\n            d_in=cfg[\"emb_dim\"], \n            d_out=cfg[\"emb_dim\"], \n            context_length=cfg[\"context_length\"],\n            num_heads=cfg[\"n_heads\"], \n            dropout=cfg[\"drop_rate\"],\n            qkv_bias=cfg[\"qkv_bias\"])\n        \n        self.ff = FeedForward(cfg)\n        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x):\n\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut\n\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut\n        return x\n\n\nclass DummyGPTModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n        )\n        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n\n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n        x = tok_embeds + pos_embeds\n        x = self.drop_emb(x)\n        x = self.trf_blocks(x)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:54.338402Z","iopub.execute_input":"2025-05-25T05:47:54.338650Z","iopub.status.idle":"2025-05-25T05:47:54.356645Z","shell.execute_reply.started":"2025-05-25T05:47:54.338630Z","shell.execute_reply":"2025-05-25T05:47:54.355945Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0) \n    return encoded_tensor\n\ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0) \n    return tokenizer.decode(flat.tolist())\n    \ndef generate_text_simple(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None): \n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -context_size:]\n        with torch.no_grad():\n            logits = model(idx_cond)\n\n        logits = logits[:, -1, :]\n\n        if top_k is not None:\n            top_logits, _ = torch.topk(logits, top_k)\n            min_val = top_logits[:, -1]\n            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n            \n        if temperature > 0.0:   \n            logits = logits / temperature\n            probs = torch.softmax(logits, dim=-1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n        else: \n            probas = torch.softmax(logits, dim=-1)\n            idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n        if idx_next == eos_id: \n            break\n\n        idx = torch.cat((idx, idx_next), dim=1)\n\n    return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:56:58.812556Z","iopub.execute_input":"2025-05-25T05:56:58.813198Z","iopub.status.idle":"2025-05-25T05:56:58.820290Z","shell.execute_reply.started":"2025-05-25T05:56:58.813176Z","shell.execute_reply":"2025-05-25T05:56:58.819523Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"train_ratio = 0.90\nsplit_idx = int(train_ratio * len(raw_text))\ntrain_data = raw_text[:split_idx]\nval_data = raw_text[split_idx:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:54.373570Z","iopub.execute_input":"2025-05-25T05:47:54.373816Z","iopub.status.idle":"2025-05-25T05:47:54.386382Z","shell.execute_reply.started":"2025-05-25T05:47:54.373785Z","shell.execute_reply":"2025-05-25T05:47:54.385585Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"torch.manual_seed(123)\n\ndef create_dataloader_v1(txt, batch_size=4, max_length=256,\n                         stride=128, shuffle=True, drop_last=True,\n                         num_workers=0):\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        drop_last=drop_last,\n        num_workers=num_workers\n    )\n\n    return dataloader\n\ntrain_loader = create_dataloader_v1(\n    train_data,\n    batch_size=8,\n    max_length=GPT_CONFIG_124M[\"context_length\"],\n    stride=GPT_CONFIG_124M[\"context_length\"],\n    drop_last=True,\n    shuffle=True,\n    num_workers=0\n)\nval_loader = create_dataloader_v1(\n    val_data,\n    batch_size=8,\n    max_length=GPT_CONFIG_124M[\"context_length\"],\n    stride=GPT_CONFIG_124M[\"context_length\"],\n    drop_last=False,\n    shuffle=False,\n    num_workers=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:54.387226Z","iopub.execute_input":"2025-05-25T05:47:54.387482Z","iopub.status.idle":"2025-05-25T05:47:54.420785Z","shell.execute_reply.started":"2025-05-25T05:47:54.387460Z","shell.execute_reply":"2025-05-25T05:47:54.420266Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def calc_loss_batch(input_batch, target_batch, model, device):\n    input_batch = input_batch.to(device)\n    target_batch = target_batch.to(device)      \n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n    return loss\n\ndef calc_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0.\n    if len(data_loader) == 0:\n        return float(\"nan\")\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        num_batches = min(num_batches, len(data_loader))\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num_batches:\n            loss = calc_loss_batch(input_batch, target_batch, model, device)\n            total_loss += loss.item()\n        else:\n            break\n    return total_loss / num_batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:47:54.421602Z","iopub.execute_input":"2025-05-25T05:47:54.421798Z","iopub.status.idle":"2025-05-25T05:47:54.427004Z","shell.execute_reply.started":"2025-05-25T05:47:54.421784Z","shell.execute_reply":"2025-05-25T05:47:54.426293Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    model.eval()  #1\n    with torch.no_grad():                    \n        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n    model.train()\n    return train_loss, val_loss\n\ndef generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_emb.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text_simple(model=model, idx=encoded,max_new_tokens=50, context_size=context_size)\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(decoded_text.replace(\"\\n\", \" \"))      #1\n    model.train()\n    \ndef train_model_simple(model, train_loader, val_loader,\n                       optimizer, device, num_epochs,\n                       eval_freq, eval_iter, start_context, tokenizer):\n    train_losses, val_losses, track_tokens_seen = [], [], []    #1\n    tokens_seen, global_step = 0, -1\n\n    for epoch in range(num_epochs):\n        model.train()\n        for input_batch, target_batch in train_loader:\n            optimizer.zero_grad()\n            loss = calc_loss_batch(input_batch, target_batch, model, device)\n            loss.backward()\n            optimizer.step()\n            tokens_seen += input_batch.numel()\n            global_step += 1\n\n            if global_step % eval_freq == 0:\n                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n                train_losses.append(train_loss)\n                val_losses.append(val_loss)\n                track_tokens_seen.append(tokens_seen)\n                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n                      f\"Train loss {train_loss:.3f}, \"\n                      f\"Val loss {val_loss:.3f}\"\n                )\n\n        generate_and_print_sample(model, tokenizer, device, start_context)\n    return train_losses, val_losses, track_tokens_seen\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:57:22.405068Z","iopub.execute_input":"2025-05-25T05:57:22.405586Z","iopub.status.idle":"2025-05-25T05:57:22.413309Z","shell.execute_reply.started":"2025-05-25T05:57:22.405563Z","shell.execute_reply":"2025-05-25T05:57:22.412618Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nstart_context = \"Hello, I am\"\nencoded_tensor = text_to_token_ids(start_context, tokenizer)\nprint(\"encoded_tensor.shape:\", encoded_tensor.shape)\n\ntorch.manual_seed(123)\nmodel = DummyGPTModel(GPT_CONFIG_124M)\nmodel.to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n\nnum_epochs = 10\ntrain_losses, val_losses, tokens_seen = train_model_simple(\n    model, train_loader, val_loader, optimizer, device,\n    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n    start_context=\"Every effort moves you\", tokenizer=tokenizer\n)\n\nmodel.to(\"cpu\")\n\nmodel.eval()\nout = generate_text_simple(\n    model=model,\n    idx=encoded_tensor, \n    max_new_tokens=6, \n    context_size=GPT_CONFIG_124M[\"context_length\"],\n    top_k=25,\n    temperature=1.4\n)\nprint(\"Output:\", out)\nprint(\"Output length:\", len(out[0]))\ndecoded_text = tokenizer.decode(out.squeeze(0).tolist())\nprint(decoded_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:57:28.973487Z","iopub.execute_input":"2025-05-25T05:57:28.973783Z","iopub.status.idle":"2025-05-25T05:57:44.896772Z","shell.execute_reply.started":"2025-05-25T05:57:28.973762Z","shell.execute_reply":"2025-05-25T05:57:44.896073Z"}},"outputs":[{"name":"stdout","text":"encoded_tensor.shape: torch.Size([1, 4])\nEp 1 (Step 000000): Train loss 9.614, Val loss 9.836\nEvery effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\nEvery effort moves you, the, the the the, the, the, the the, the, the, the the,, the,, the, the, the,, the the, the, the, the, the, the,,, the, the\nEp 3 (Step 000005): Train loss 7.379, Val loss 7.903\nEvery effort moves you, the, the, the, the, the,, the, the, the, the,,, the,, the,,, the,, the, the, the, the,, the,, the,, the, the\nEvery effort moves you, the, the the the.                                           \nEvery effort moves you. \". \"I \" \"I. \" I had the \", and the, I had the, and I had the the the \". \"I had the, and the, and I had the\nEp 6 (Step 000010): Train loss 5.819, Val loss 7.270\nEvery effort moves you. I had the the the, and I had the of the. I had the, I had the of the, I had the, and I had the the the, and the of the of the of the of the of the of the of\nEvery effort moves you. I had the of the of the his to the of the. I had. I had the, and I had been. I had. I had been the of the, and I had been, and, and--, and I had the\nEp 8 (Step 000015): Train loss 4.449, Val loss 6.523\nEvery effort moves you know the to the picture. Gisburn--I had been. I had been, and I had been the, I had been to the picture, and I had been. Gisburn had been the picture, and I had been the of\nEvery effort moves you know the picture.    \"I the picture.   \"I was the picture--I was I was.   \"I the picture my the donkey--I had been the picture and I was.   \nEvery effort moves you know the, and in the picture--I to me--I me. \"I was, in a little to see it to see a little, in the picture to have.   \"I, and--I, and I was\nOutput: tensor([[15496,    11,   314,   716,    11,   287,   616,     1,   319,   326]])\nOutput length: 10\nHello, I am, in my\" on that\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"torch.save({\n    \"model_state_dict\": model.state_dict(),\n    \"optimizer_state_dict\": optimizer.state_dict(),\n    }, \n    \"model_and_optimizer.pth\"\n)\n\n# checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n# model = GPTModel(GPT_CONFIG_124M)\n# model.load_state_dict(checkpoint[\"model_state_dict\"])\n# optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n# optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n# model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T05:59:50.262781Z","iopub.execute_input":"2025-05-25T05:59:50.263448Z","iopub.status.idle":"2025-05-25T05:59:53.138070Z","shell.execute_reply.started":"2025-05-25T05:59:50.263424Z","shell.execute_reply":"2025-05-25T05:59:53.137290Z"}},"outputs":[],"execution_count":26}]}