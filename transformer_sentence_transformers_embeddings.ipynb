{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:47:48.660428Z","iopub.execute_input":"2025-11-29T05:47:48.660661Z","iopub.status.idle":"2025-11-29T05:47:50.236666Z","shell.execute_reply.started":"2025-11-29T05:47:48.660635Z","shell.execute_reply":"2025-11-29T05:47:50.235795Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load MNLI dataset from GLUE\n# 0 = entailment, 1 = neutral, 2 = contradiction\ntrain_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\ntrain_dataset = train_dataset.remove_columns(\"idx\")\nprint(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:47:58.722752Z","iopub.execute_input":"2025-11-29T05:47:58.723027Z","iopub.status.idle":"2025-11-29T05:48:10.534909Z","shell.execute_reply.started":"2025-11-29T05:47:58.723006Z","shell.execute_reply":"2025-11-29T05:48:10.534136Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dde93e68907042b0a4d1c8b7caf1fbf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mnli/train-00000-of-00001.parquet:   0%|          | 0.00/52.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d26729068674c4a85bb3b022fdd4818"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mnli/validation_matched-00000-of-00001.p(…):   0%|          | 0.00/1.21M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2f84a190e4244c4b035d41e67583e57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mnli/validation_mismatched-00000-of-0000(…):   0%|          | 0.00/1.25M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"468112ec25684d1f9e0d90afe81428fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mnli/test_matched-00000-of-00001.parquet:   0%|          | 0.00/1.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69fb132068ba41a597655180a6c2d9e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mnli/test_mismatched-00000-of-00001.parq(…):   0%|          | 0.00/1.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f75417e5c78461782bb731b03f8304f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9e9ff2fd050482c94a80487bb6480b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"514840caac87417e969ee2c51cfee664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"894dcfb2be54458ca033aa43f6a0b1eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b5729d5b26b4e8c858734a43bef0f6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9f8bf9f9adb4a6b95c652978b8c96f4"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['premise', 'hypothesis', 'label'],\n    num_rows: 50000\n})\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(train_dataset[2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:48:37.794215Z","iopub.execute_input":"2025-11-29T05:48:37.795004Z","iopub.status.idle":"2025-11-29T05:48:37.799657Z","shell.execute_reply.started":"2025-11-29T05:48:37.794979Z","shell.execute_reply":"2025-11-29T05:48:37.798872Z"}},"outputs":[{"name":"stdout","text":"{'premise': 'One of our number will carry out your instructions minutely.', 'hypothesis': 'A member of my team will execute your orders with immense precision.', 'label': 0}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nembedding_model = SentenceTransformer('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:50:31.672318Z","iopub.execute_input":"2025-11-29T05:50:31.673211Z","iopub.status.idle":"2025-11-29T05:51:07.789819Z","shell.execute_reply.started":"2025-11-29T05:50:31.673177Z","shell.execute_reply":"2025-11-29T05:51:07.789137Z"}},"outputs":[{"name":"stderr","text":"2025-11-29 05:50:40.804080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764395440.970474      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764395441.020463      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stderr","text":"WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b82884de344f6681ec1f825ad44cf0"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5a61b0713ce485e83a1974372b83e2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"907b552b2ac84c2e868a17803606de86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d972fae5a69e48129035594b58ca325f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc262c3f6fcd415b9fccd364540aa2c8"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from sentence_transformers import losses\n\ntrain_loss = losses.SoftmaxLoss(\n    model=embedding_model, \n    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n    num_labels=3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:51:47.465357Z","iopub.execute_input":"2025-11-29T05:51:47.465686Z","iopub.status.idle":"2025-11-29T05:51:47.480960Z","shell.execute_reply.started":"2025-11-29T05:51:47.465664Z","shell.execute_reply":"2025-11-29T05:51:47.480409Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n\n# Create an embedding similarity evaluator for STSB\nval_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\nevaluator = EmbeddingSimilarityEvaluator(sentences1=val_sts[\"sentence1\"],sentences2=val_sts[\"sentence2\"],\n    scores=[score/5 for score in val_sts[\"label\"]],\n    main_similarity=\"cosine\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:52:16.494802Z","iopub.execute_input":"2025-11-29T05:52:16.495612Z","iopub.status.idle":"2025-11-29T05:52:20.333588Z","shell.execute_reply.started":"2025-11-29T05:52:16.495581Z","shell.execute_reply":"2025-11-29T05:52:20.333020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"stsb/train-00000-of-00001.parquet:   0%|          | 0.00/502k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df76782438b42e0989192e69537edf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stsb/validation-00000-of-00001.parquet:   0%|          | 0.00/151k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df33c7693f2418faa0abf2e73718473"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stsb/test-00000-of-00001.parquet:   0%|          | 0.00/114k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa44828e75b4679b83d9333065087b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c3db2d297f84191b65f594d6264f97a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99fb7699deec48058423fae66548a367"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dd307e005eb41b59aeeefbd1f8ce247"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from sentence_transformers.training_args import SentenceTransformerTrainingArguments\nfrom sentence_transformers.trainer import SentenceTransformerTrainer\n\n\n# Define the training arguments\nargs = SentenceTransformerTrainingArguments(\n    output_dir=\"base_embedding_model\",\n    num_train_epochs=1,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    warmup_steps=100,\n    fp16=True,\n    eval_steps=100,\n    logging_steps=100,\n    report_to=\"none\"\n)\n\n\n# Train embedding model\ntrainer = SentenceTransformerTrainer(\n    model=embedding_model,\n    args=args,\n    train_dataset=train_dataset,\n    loss=train_loss,\n    evaluator=evaluator\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:54:07.240861Z","iopub.execute_input":"2025-11-29T05:54:07.241589Z","iopub.status.idle":"2025-11-29T06:02:38.451186Z","shell.execute_reply.started":"2025-11-29T05:54:07.241561Z","shell.execute_reply":"2025-11-29T06:02:38.450609Z"}},"outputs":[{"name":"stderr","text":"WARNING:sentence_transformers.data_collator:Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\ndataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1563/1563 08:29, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.077400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.942600</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.884100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.839800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.829100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.823400</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.807700</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.787600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.775600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.766300</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.745900</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.727300</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.743800</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.709000</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.745100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1563, training_loss=0.8104058263855566, metrics={'train_runtime': 510.2327, 'train_samples_per_second': 97.995, 'train_steps_per_second': 3.063, 'total_flos': 0.0, 'train_loss': 0.8104058263855566, 'epoch': 1.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"evaluator(embedding_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T06:03:42.202550Z","iopub.execute_input":"2025-11-29T06:03:42.203244Z","iopub.status.idle":"2025-11-29T06:03:45.754032Z","shell.execute_reply.started":"2025-11-29T06:03:42.203221Z","shell.execute_reply":"2025-11-29T06:03:45.753403Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'pearson_cosine': 0.5385758338470295, 'spearman_cosine': 0.6074462887719765}"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Multiple negatives ranking(MNR) Loss","metadata":{}},{"cell_type":"code","source":"import random\nfrom tqdm import tqdm\nfrom datasets import Dataset\n\nmnli = train_dataset.filter(lambda x: True if x[\"label\"] == 0 else False)\n\n# Prepare data and add a soft negative\nmnr_train_dataset = {\"anchor\": [], \"positive\": [], \"negative\": []}\nsoft_negatives = list(mnli[\"hypothesis\"])  \nrandom.shuffle(soft_negatives)\nfor row, soft_negative in tqdm(zip(mnli, soft_negatives)):\n    mnr_train_dataset[\"anchor\"].append(row[\"premise\"])\n    mnr_train_dataset[\"positive\"].append(row[\"hypothesis\"])\n    mnr_train_dataset[\"negative\"].append(soft_negative)\ntrain_dataset = Dataset.from_dict(mnr_train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T06:13:07.965185Z","iopub.execute_input":"2025-11-29T06:13:07.965813Z","iopub.status.idle":"2025-11-29T06:13:09.818129Z","shell.execute_reply.started":"2025-11-29T06:13:07.965790Z","shell.execute_reply":"2025-11-29T06:13:09.817434Z"}},"outputs":[{"name":"stderr","text":"16875it [00:01, 15569.47it/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"evaluator = EmbeddingSimilarityEvaluator(\n    sentences1=val_sts[\"sentence1\"],\n    sentences2=val_sts[\"sentence2\"],\n    scores=[score/5 for score in val_sts[\"label\"]],\n    main_similarity=\"cosine\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T06:13:30.398743Z","iopub.execute_input":"2025-11-29T06:13:30.399389Z","iopub.status.idle":"2025-11-29T06:13:30.425113Z","shell.execute_reply.started":"2025-11-29T06:13:30.399343Z","shell.execute_reply":"2025-11-29T06:13:30.424566Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from sentence_transformers import losses, SentenceTransformer\nfrom sentence_transformers.trainer import SentenceTransformerTrainer\nfrom sentence_transformers.training_args import SentenceTransformerTrainingArguments\n\n# Define model\nembedding_model = SentenceTransformer('bert-base-uncased')\n\n# Loss function\ntrain_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n\n# Define the training arguments\nargs = SentenceTransformerTrainingArguments(\n    output_dir=\"mnrloss_embedding_model\",\n    num_train_epochs=1,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    warmup_steps=100,\n    fp16=True,\n    eval_steps=100,\n    logging_steps=100,\n    report_to=\"none\"\n)\n\n# Train model\ntrainer = SentenceTransformerTrainer(\n    model=embedding_model,\n    args=args,\n    train_dataset=train_dataset,\n    loss=train_loss,\n    evaluator=evaluator\n)\ntrainer.train()\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T06:14:58.515572Z","iopub.execute_input":"2025-11-29T06:14:58.516214Z","iopub.status.idle":"2025-11-29T06:18:42.866758Z","shell.execute_reply.started":"2025-11-29T06:14:58.516192Z","shell.execute_reply":"2025-11-29T06:18:42.866008Z"}},"outputs":[{"name":"stderr","text":"WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [528/528 03:41, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.341300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.102300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.078300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.068000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.065200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=528, training_loss=0.127442610986305, metrics={'train_runtime': 222.1799, 'train_samples_per_second': 75.952, 'train_steps_per_second': 2.376, 'total_flos': 0.0, 'train_loss': 0.127442610986305, 'epoch': 1.0})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"evaluator(embedding_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T06:18:56.970442Z","iopub.execute_input":"2025-11-29T06:18:56.971037Z","iopub.status.idle":"2025-11-29T06:19:00.620661Z","shell.execute_reply.started":"2025-11-29T06:18:56.971014Z","shell.execute_reply":"2025-11-29T06:19:00.619876Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'pearson_cosine': 0.8023416466468334, 'spearman_cosine': 0.8070421291847529}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# The sentences to encode\nsentences = [\n    \"The weather is lovely today.\",\n    \"It's so sunny outside!\",\n    \"He drove to the stadium.\",\n]\n\n# 2. Calculate embeddings by calling model.encode()\nembeddings = embedding_model.encode(sentences)\nprint(embeddings.shape)\n\n# 3. Calculate the embedding similarities\nsimilarities = embedding_model.similarity(embeddings, embeddings)\nprint(similarities)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T06:19:05.284908Z","iopub.execute_input":"2025-11-29T06:19:05.285209Z","iopub.status.idle":"2025-11-29T06:19:05.327256Z","shell.execute_reply.started":"2025-11-29T06:19:05.285188Z","shell.execute_reply":"2025-11-29T06:19:05.326548Z"}},"outputs":[{"name":"stdout","text":"(3, 768)\ntensor([[1.0000, 0.7521, 0.1056],\n        [0.7521, 1.0000, 0.1514],\n        [0.1056, 0.1514, 1.0000]])\n","output_type":"stream"}],"execution_count":15}]}