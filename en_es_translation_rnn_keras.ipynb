{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom path import Path \nimport numpy as np\n\nurl = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\npath = keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\", extract=True)\ntext = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()\ntext = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\npairs = [line.split(\"\\t\") for line in text.splitlines()]\n\nnp.random.shuffle(pairs)\nsentences_en, sentences_es = zip(*pairs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:44:07.554303Z","iopub.execute_input":"2025-04-26T15:44:07.554843Z","iopub.status.idle":"2025-04-26T15:44:08.089736Z","shell.execute_reply.started":"2025-04-26T15:44:07.554822Z","shell.execute_reply":"2025-04-26T15:44:08.089164Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"vocab_size = 1500\nencoder_text_vectorization = keras.layers.TextVectorization(vocab_size, output_sequence_length = 64)\ndecoder_text_vectorization = keras.layers.TextVectorization(vocab_size, output_sequence_length = 64)\n\nencoder_text_vectorization.adapt(sentences_en)\ndecoder_text_vectorization.adapt([f\"startofseq {sentence} endofseq\" for sentence in sentences_es])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:46:44.530700Z","iopub.execute_input":"2025-04-26T15:46:44.530962Z","iopub.status.idle":"2025-04-26T15:46:46.919812Z","shell.execute_reply.started":"2025-04-26T15:46:44.530945Z","shell.execute_reply":"2025-04-26T15:46:46.919255Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1745682405.964729      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1745682405.965372      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"X_train_enc = tf.constant(sentences_en[:100_000])\nX_valid_enc = tf.constant(sentences_en[100_000:])\n\nX_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\nX_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n\nY_train = decoder_text_vectorization([f\"{s} endofseq\" for s in sentences_es[:100_000]])\nY_valid = decoder_text_vectorization([f\"{s} endofseq\" for s in sentences_es[100_000:]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:49:22.935668Z","iopub.execute_input":"2025-04-26T15:49:22.936388Z","iopub.status.idle":"2025-04-26T15:49:25.809780Z","shell.execute_reply.started":"2025-04-26T15:49:22.936363Z","shell.execute_reply":"2025-04-26T15:49:25.809267Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"encoder_inputs = keras.layers.Input(shape=[], dtype=tf.string)\ndecoder_inputs = keras.layers.Input(shape=[], dtype=tf.string)\n\nencoder_x = encoder_text_vectorization(encoder_inputs)\ndecoder_x = decoder_text_vectorization(encoder_inputs)\n\nencoder_x = keras.layers.Embedding(input_dim = vocab_size, output_dim = 128, mask_zero=True)(encoder_x)\ndecoder_x = keras.layers.Embedding(input_dim = vocab_size, output_dim = 128, mask_zero=True)(decoder_x)\n\nencoder_outputs, *encoder_state = keras.layers.LSTM(512, return_state = True)(encoder_x)\n\n\ndecoder_x = keras.layers.LSTM(512, return_sequences=True)(decoder_x, initial_state=encoder_state)\noutput = keras.layers.Dense(vocab_size, activation='softmax')(decoder_x)\n\nmodel = keras.Model(inputs = [encoder_inputs,decoder_inputs], outputs = [output])\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T16:05:38.015856Z","iopub.execute_input":"2025-04-26T16:05:38.016510Z","iopub.status.idle":"2025-04-26T16:05:38.343833Z","shell.execute_reply.started":"2025-04-26T16:05:38.016487Z","shell.execute_reply":"2025-04-26T16:05:38.343087Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model.fit((X_train_enc, X_train_dec), Y_train, epochs=10, validation_data=((X_valid_enc, X_valid_dec), Y_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T16:05:41.590937Z","iopub.execute_input":"2025-04-26T16:05:41.591206Z","iopub.status.idle":"2025-04-26T16:18:16.393098Z","shell.execute_reply.started":"2025-04-26T16:05:41.591185Z","shell.execute_reply":"2025-04-26T16:18:16.392340Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 24ms/step - accuracy: 0.8223 - loss: 4.4265 - val_accuracy: 0.9230 - val_loss: 3.1977\nEpoch 2/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9245 - loss: 2.9723 - val_accuracy: 0.9294 - val_loss: 2.5930\nEpoch 3/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9316 - loss: 2.3864 - val_accuracy: 0.9326 - val_loss: 2.3468\nEpoch 4/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9364 - loss: 2.0660 - val_accuracy: 0.9344 - val_loss: 2.2340\nEpoch 5/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9394 - loss: 1.8443 - val_accuracy: 0.9301 - val_loss: 2.1917\nEpoch 6/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9421 - loss: 1.6587 - val_accuracy: 0.9245 - val_loss: 2.1988\nEpoch 7/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9445 - loss: 1.5061 - val_accuracy: 0.9333 - val_loss: 2.2153\nEpoch 8/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9460 - loss: 1.3657 - val_accuracy: 0.9255 - val_loss: 2.2617\nEpoch 9/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9415 - loss: 1.2445 - val_accuracy: 0.9258 - val_loss: 2.3085\nEpoch 10/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9457 - loss: 1.1407 - val_accuracy: 0.8669 - val_loss: 2.3689\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79648e3b60d0>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"max_length = 50\ndef translate(sentence_en):\n    translation = \"\"\n    for word_idx in range(max_length):\n        X = tf.constant([sentence_en])  # encoder input\n        X_dec = tf.constant([\"startofseq \" + translation])  # decoder input\n        predictions = model.predict((X, X_dec))\n        y_proba = predictions[0, word_idx]  # last token's probas\n        predicted_word_id = np.argmax(y_proba)\n        predicted_word = decoder_text_vectorization.get_vocabulary()[predicted_word_id]\n        if predicted_word == \"endofseq\":\n            break\n        translation += \" \" + predicted_word\n    return translation.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T16:22:10.234793Z","iopub.execute_input":"2025-04-26T16:22:10.235041Z","iopub.status.idle":"2025-04-26T16:22:10.240328Z","shell.execute_reply.started":"2025-04-26T16:22:10.235024Z","shell.execute_reply":"2025-04-26T16:22:10.239603Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"translate(\"I like soccer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T16:22:12.090709Z","iopub.execute_input":"2025-04-26T16:22:12.090988Z","iopub.status.idle":"2025-04-26T16:22:12.477202Z","shell.execute_reply.started":"2025-04-26T16:22:12.090967Z","shell.execute_reply":"2025-04-26T16:22:12.476622Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'me gusta el fútbol'"},"metadata":{}}],"execution_count":24}]}