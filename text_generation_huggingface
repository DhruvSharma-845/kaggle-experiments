{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:10:27.109957Z","iopub.execute_input":"2025-06-17T15:10:27.110205Z","iopub.status.idle":"2025-06-17T15:10:45.179479Z","shell.execute_reply.started":"2025-06-17T15:10:27.110179Z","shell.execute_reply":"2025-06-17T15:10:45.178895Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_name = \"gpt2-xl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:10:48.104352Z","iopub.execute_input":"2025-06-17T15:10:48.104615Z","iopub.status.idle":"2025-06-17T15:10:48.108515Z","shell.execute_reply.started":"2025-06-17T15:10:48.104596Z","shell.execute_reply":"2025-06-17T15:10:48.107866Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:10:50.699363Z","iopub.execute_input":"2025-06-17T15:10:50.699814Z","iopub.status.idle":"2025-06-17T15:10:52.022139Z","shell.execute_reply.started":"2025-06-17T15:10:50.699779Z","shell.execute_reply":"2025-06-17T15:10:52.021286Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288c891ecaf1430cb4a38adc6ebeb17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd990c742f8643ee98bedd89c5546d42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ab824cea5a47128087ec05f91573ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27c82b2c87a24a7db1aa37869770a91e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37bf73a70d044ad28255567ea72ffda1"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_name).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:10:56.956248Z","iopub.execute_input":"2025-06-17T15:10:56.957272Z","iopub.status.idle":"2025-06-17T15:12:02.699852Z","shell.execute_reply.started":"2025-06-17T15:10:56.957233Z","shell.execute_reply":"2025-06-17T15:12:02.698824Z"}},"outputs":[{"name":"stderr","text":"2025-06-17 15:11:01.728347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750173062.171526      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750173062.300980      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5057388853e47e0a8dd5f47f6c7fe0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4786f92a34854b11ba165cf13e26b5b4"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"input_txt = \"Transformers are the\"\ntokenized_input = tokenizer(input_txt, return_tensors=\"pt\")\nprint(tokenized_input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:15:01.762630Z","iopub.execute_input":"2025-06-17T15:15:01.763930Z","iopub.status.idle":"2025-06-17T15:15:01.799446Z","shell.execute_reply.started":"2025-06-17T15:15:01.763894Z","shell.execute_reply":"2025-06-17T15:15:01.798683Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[41762,   364,   389,   262]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"input_ids = tokenized_input.input_ids.to(device)\nprint(input_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:21:51.087066Z","iopub.execute_input":"2025-06-17T15:21:51.087776Z","iopub.status.idle":"2025-06-17T15:21:51.092394Z","shell.execute_reply.started":"2025-06-17T15:21:51.087744Z","shell.execute_reply":"2025-06-17T15:21:51.091765Z"}},"outputs":[{"name":"stdout","text":"tensor([[41762,   364,   389,   262]], device='cuda:0')\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"n_steps = 8\nwith torch.no_grad():\n    for i in range(n_steps):\n        print(\"Iteration {}\".format(i))\n        output = model(input_ids=input_ids)\n        next_token_logits = output.logits[0, -1, :]\n        print(next_token_logits)\n\n        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n        print(next_token_probs)\n        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n        print(sorted_ids)\n\n        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n        print(input_ids)\n\n        print(tokenizer.decode(input_ids[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T15:21:53.001812Z","iopub.execute_input":"2025-06-17T15:21:53.002485Z","iopub.status.idle":"2025-06-17T15:21:53.371459Z","shell.execute_reply.started":"2025-06-17T15:21:53.002459Z","shell.execute_reply":"2025-06-17T15:21:53.370892Z"}},"outputs":[{"name":"stdout","text":"Iteration 0\ntensor([ 0.3186,  0.8100, -2.9974,  ..., -3.2712, -4.3837,  0.8114],\n       device='cuda:0')\ntensor([1.5103e-05, 2.4687e-05, 5.4820e-07,  ..., 4.1690e-07, 1.3704e-07,\n        2.4722e-05], device='cuda:0')\ntensor([ 749,  691, 1266,  ...,  195,  208,  181], device='cuda:0')\ntensor([[41762,   364,   389,   262,   749]], device='cuda:0')\nTransformers are the most\nIteration 1\ntensor([ 0.7832,  1.4650, -1.6474,  ..., -2.6462, -0.0434, -0.5486],\n       device='cuda:0')\ntensor([1.2362e-05, 2.4447e-05, 1.0877e-06,  ..., 4.0064e-07, 5.4090e-06,\n        3.2637e-06], device='cuda:0')\ntensor([2968, 3665, 2219,  ...,  212,  182,  205], device='cuda:0')\ntensor([[41762,   364,   389,   262,   749,  2968]], device='cuda:0')\nTransformers are the most popular\nIteration 2\ntensor([ 3.6633,  2.2498, -3.2975,  ..., -3.3829, -6.3650,  1.3503],\n       device='cuda:0')\ntensor([7.6166e-04, 1.8530e-04, 7.2231e-07,  ..., 6.6319e-07, 3.3615e-08,\n        7.5373e-05], device='cuda:0')\ntensor([13373, 14958, 39185,  ...,   200,   208,   195], device='cuda:0')\ntensor([[41762,   364,   389,   262,   749,  2968, 13373]], device='cuda:0')\nTransformers are the most popular toy\nIteration 3\ntensor([ 3.8043,  2.5449, -1.9320,  ..., -6.0522, -6.2231,  0.8133],\n       device='cuda:0')\ntensor([2.8581e-04, 8.1115e-05, 9.2219e-07,  ..., 1.4977e-08, 1.2625e-08,\n        1.4358e-05], device='cuda:0')\ntensor([1627,  287,  286,  ...,  200,  195,  194], device='cuda:0')\ntensor([[41762,   364,   389,   262,   749,  2968, 13373,  1627]],\n       device='cuda:0')\nTransformers are the most popular toy line\nIteration 4\ntensor([ 5.7981,  3.5864, -0.2252,  ..., -9.2710, -5.4710,  1.6808],\n       device='cuda:0')\ntensor([1.2549e-03, 1.3742e-04, 3.0387e-06,  ..., 3.5821e-10, 1.6012e-08,\n        2.0438e-05], device='cuda:0')\ntensor([287, 286,  11,  ..., 200, 191, 195], device='cuda:0')\ntensor([[41762,   364,   389,   262,   749,  2968, 13373,  1627,   287]],\n       device='cuda:0')\nTransformers are the most popular toy line in\nIteration 5\ntensor([-0.2814, -0.0597, -4.0544,  ..., -6.9407, -7.8547, -1.5933],\n       device='cuda:0')\ntensor([1.8337e-06, 2.2888e-06, 4.2146e-08,  ..., 2.3510e-09, 9.4249e-10,\n        4.9383e-07], device='cuda:0')\ntensor([  262,  2106,  2253,  ...,   193,   195, 30905], device='cuda:0')\ntensor([[41762,   364,   389,   262,   749,  2968, 13373,  1627,   287,   262]],\n       device='cuda:0')\nTransformers are the most popular toy line in the\nIteration 6\ntensor([ 0.1605,  0.2670, -2.1840,  ..., -7.7966, -5.2849,  0.2788],\n       device='cuda:0')\ntensor([1.6368e-06, 1.8206e-06, 1.5695e-07,  ..., 5.7313e-10, 7.0647e-09,\n        1.8423e-06], device='cuda:0')\ntensor([  995,  1578,  2106,  ...,   194, 30905,   195], device='cuda:0')\ntensor([[41762,   364,   389,   262,   749,  2968, 13373,  1627,   287,   262,\n           995]], device='cuda:0')\nTransformers are the most popular toy line in the world\nIteration 7\ntensor([ 8.1076,  4.7803,  1.1597,  ..., -9.2347, -5.6519,  3.2676],\n       device='cuda:0')\ntensor([1.0412e-02, 3.7368e-04, 1.0002e-05,  ..., 3.0608e-10, 1.1011e-08,\n        8.2325e-05], device='cuda:0')\ntensor([ 11,  13, 290,  ..., 191, 201, 200], device='cuda:0')\ntensor([[41762,   364,   389,   262,   749,  2968, 13373,  1627,   287,   262,\n           995,    11]], device='cuda:0')\nTransformers are the most popular toy line in the world,\n","output_type":"stream"}],"execution_count":11}]}