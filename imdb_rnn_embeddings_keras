{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:15:24.833172Z","iopub.execute_input":"2025-04-19T06:15:24.833437Z","iopub.status.idle":"2025-04-19T06:15:27.657861Z","shell.execute_reply.started":"2025-04-19T06:15:24.833415Z","shell.execute_reply":"2025-04-19T06:15:27.657122Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n!tar -xf aclImdb_v1.tar.gz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:15:27.658562Z","iopub.execute_input":"2025-04-19T06:15:27.659206Z","iopub.status.idle":"2025-04-19T06:15:39.924195Z","shell.execute_reply.started":"2025-04-19T06:15:27.659183Z","shell.execute_reply":"2025-04-19T06:15:39.923127Z"}},"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 80.2M  100 80.2M    0     0  12.9M      0  0:00:06  0:00:06 --:--:-- 18.1M\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!rm -r aclImdb/train/unsup","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:15:39.926675Z","iopub.execute_input":"2025-04-19T06:15:39.926991Z","iopub.status.idle":"2025-04-19T06:15:41.012483Z","shell.execute_reply.started":"2025-04-19T06:15:39.926961Z","shell.execute_reply":"2025-04-19T06:15:41.011061Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!cat aclImdb/train/pos/4077_10.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:15:41.014411Z","iopub.execute_input":"2025-04-19T06:15:41.014797Z","iopub.status.idle":"2025-04-19T06:15:41.140581Z","shell.execute_reply.started":"2025-04-19T06:15:41.014770Z","shell.execute_reply":"2025-04-19T06:15:41.139758Z"}},"outputs":[{"name":"stdout","text":"I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nprint('Number of files in training positive set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/train/pos'))))\nprint('Number of files in training negative set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/train/neg'))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:15:41.141774Z","iopub.execute_input":"2025-04-19T06:15:41.142051Z","iopub.status.idle":"2025-04-19T06:15:41.163157Z","shell.execute_reply.started":"2025-04-19T06:15:41.142026Z","shell.execute_reply":"2025-04-19T06:15:41.162236Z"}},"outputs":[{"name":"stdout","text":"Number of files in training positive set is 12500\nNumber of files in training negative set is 12500\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"dataset_dir = '/kaggle/working/aclImdb'\ntraining_set_dir = os.path.join(dataset_dir, 'train')\nvalidation_set_dir = os.path.join(dataset_dir, 'valid')\ntest_set_dir = os.path.join(dataset_dir, 'test')\n\nos.makedirs(validation_set_dir, exist_ok=True) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:15:41.164199Z","iopub.execute_input":"2025-04-19T06:15:41.164514Z","iopub.status.idle":"2025-04-19T06:15:41.170549Z","shell.execute_reply.started":"2025-04-19T06:15:41.164486Z","shell.execute_reply":"2025-04-19T06:15:41.169731Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"for category in ['pos', 'neg']:\n    source_directory = os.path.join(training_set_dir, category)\n    destination_directory = os.path.join(validation_set_dir, category)\n    os.makedirs(destination_directory, exist_ok=True)\n    source_files = os.listdir(source_directory)\n    num_files_to_move = int(0.2 * len(source_files))\n    for i in range(1, num_files_to_move + 1):\n        os.rename(os.path.join(source_directory, source_files[i]), os.path.join(destination_directory, source_files[i]))\n\nprint('Number of files in training positive set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/train/pos'))))\nprint('Number of files in training negative set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/train/neg'))))\nprint('Number of files in validation positive set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/valid/pos'))))\nprint('Number of files in validation negative set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/valid/neg'))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:15:41.171506Z","iopub.execute_input":"2025-04-19T06:15:41.171843Z","iopub.status.idle":"2025-04-19T06:15:41.345852Z","shell.execute_reply.started":"2025-04-19T06:15:41.171816Z","shell.execute_reply":"2025-04-19T06:15:41.345113Z"}},"outputs":[{"name":"stdout","text":"Number of files in training positive set is 10000\nNumber of files in training negative set is 10000\nNumber of files in validation positive set is 2500\nNumber of files in validation negative set is 2500\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from tensorflow import keras\n\ntrain_dataset = keras.utils.text_dataset_from_directory(training_set_dir, batch_size=32)\nvalid_dataset = keras.utils.text_dataset_from_directory(validation_set_dir, batch_size=32)\ntest_dataset = keras.utils.text_dataset_from_directory(test_set_dir, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:15:41.346667Z","iopub.execute_input":"2025-04-19T06:15:41.347059Z","iopub.status.idle":"2025-04-19T06:16:10.900114Z","shell.execute_reply.started":"2025-04-19T06:15:41.347033Z","shell.execute_reply":"2025-04-19T06:16:10.899344Z"}},"outputs":[{"name":"stderr","text":"2025-04-19 06:15:45.092355: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745043345.582930      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745043345.718858      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 20000 files belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1745043367.528231      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1745043367.529285      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Found 5000 files belonging to 2 classes.\nFound 25000 files belonging to 2 classes.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ntext_vectorization = layers.TextVectorization(max_tokens = 20000, output_mode = 'int', output_sequence_length=600)\ntext_only_train_ds = train_dataset.map(lambda x, y: x)\n\ntext_vectorization.adapt(text_only_train_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:16:10.902275Z","iopub.execute_input":"2025-04-19T06:16:10.902530Z","iopub.status.idle":"2025-04-19T06:16:17.684702Z","shell.execute_reply.started":"2025-04-19T06:16:10.902503Z","shell.execute_reply":"2025-04-19T06:16:17.683985Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"preprocessed_train_dataset = train_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\npreprocessed_valid_dataset = valid_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\npreprocessed_test_dataset = test_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:16:17.685485Z","iopub.execute_input":"2025-04-19T06:16:17.685780Z","iopub.status.idle":"2025-04-19T06:16:18.069907Z","shell.execute_reply.started":"2025-04-19T06:16:17.685746Z","shell.execute_reply":"2025-04-19T06:16:18.069263Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import tensorflow as tf\n\ninputs = keras.Input(shape=(None,), dtype='int64')\n# embedded = layers.Lambda(lambda x: tf.one_hot(x, depth=20000), output_shape = (None, 20000))(inputs)\nembedded = layers.Embedding(input_dim=20000, output_dim=256)(inputs)\nx = layers.Bidirectional(layers.LSTM(32))(embedded)\nx = layers.Dropout(0.5)(x) \noutputs = layers.Dense(1, activation='sigmoid')(x)\nmodel = keras.Model(inputs, outputs)\n\nmodel.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:01:53.162279Z","iopub.execute_input":"2025-04-19T07:01:53.163101Z","iopub.status.idle":"2025-04-19T07:01:53.244526Z","shell.execute_reply.started":"2025-04-19T07:01:53.163076Z","shell.execute_reply":"2025-04-19T07:01:53.243892Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m5,120,000\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m73,984\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,984</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,194,049\u001b[0m (19.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,194,049</span> (19.81 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,194,049\u001b[0m (19.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,194,049</span> (19.81 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"model.fit(preprocessed_train_dataset, validation_data=preprocessed_valid_dataset, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:02:04.795782Z","iopub.execute_input":"2025-04-19T07:02:04.796116Z","iopub.status.idle":"2025-04-19T07:06:41.538127Z","shell.execute_reply.started":"2025-04-19T07:02:04.796097Z","shell.execute_reply":"2025-04-19T07:06:41.537407Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 44ms/step - accuracy: 0.6242 - loss: 0.6312 - val_accuracy: 0.8264 - val_loss: 0.4027\nEpoch 2/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.8283 - loss: 0.4222 - val_accuracy: 0.6336 - val_loss: 1.0205\nEpoch 3/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.8603 - loss: 0.3709 - val_accuracy: 0.8706 - val_loss: 0.3129\nEpoch 4/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.8919 - loss: 0.2954 - val_accuracy: 0.8690 - val_loss: 0.3280\nEpoch 5/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.9078 - loss: 0.2534 - val_accuracy: 0.8786 - val_loss: 0.3109\nEpoch 6/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.9227 - loss: 0.2203 - val_accuracy: 0.8460 - val_loss: 0.4175\nEpoch 7/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.9348 - loss: 0.1946 - val_accuracy: 0.8706 - val_loss: 0.3445\nEpoch 8/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.9506 - loss: 0.1515 - val_accuracy: 0.8740 - val_loss: 0.3538\nEpoch 9/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.9593 - loss: 0.1227 - val_accuracy: 0.8810 - val_loss: 0.3672\nEpoch 10/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.9653 - loss: 0.1019 - val_accuracy: 0.8802 - val_loss: 0.4312\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7bd67ee75990>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(f\"Test acc: {model.evaluate(preprocessed_test_dataset)[1]:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:07:11.039266Z","iopub.execute_input":"2025-04-19T07:07:11.040002Z","iopub.status.idle":"2025-04-19T07:07:24.917407Z","shell.execute_reply.started":"2025-04-19T07:07:11.039978Z","shell.execute_reply":"2025-04-19T07:07:24.916654Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8641 - loss: 0.4816\nTest acc: 0.863\n","output_type":"stream"}],"execution_count":18}]}