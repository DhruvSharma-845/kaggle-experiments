{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n!tar -xf aclImdb_v1.tar.gz\n!rm -r aclImdb/train/unsup","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:23:35.902823Z","iopub.execute_input":"2025-04-19T11:23:35.903025Z","iopub.status.idle":"2025-04-19T11:23:48.997368Z","shell.execute_reply.started":"2025-04-19T11:23:35.903009Z","shell.execute_reply":"2025-04-19T11:23:48.996239Z"}},"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 80.2M  100 80.2M    0     0  11.2M      0  0:00:07  0:00:07 --:--:-- 18.6M\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\ndataset_dir = '/kaggle/working/aclImdb'\ntraining_set_dir = os.path.join(dataset_dir, 'train')\nvalidation_set_dir = os.path.join(dataset_dir, 'valid')\ntest_set_dir = os.path.join(dataset_dir, 'test')\n\nos.makedirs(validation_set_dir, exist_ok=True) \n\nfor category in ['pos', 'neg']:\n    source_directory = os.path.join(training_set_dir, category)\n    destination_directory = os.path.join(validation_set_dir, category)\n    os.makedirs(destination_directory, exist_ok=True)\n    source_files = os.listdir(source_directory)\n    num_files_to_move = int(0.2 * len(source_files))\n    for i in range(1, num_files_to_move + 1):\n        os.rename(os.path.join(source_directory, source_files[i]), os.path.join(destination_directory, source_files[i]))\n\nprint('Number of files in training positive set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/train/pos'))))\nprint('Number of files in training negative set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/train/neg'))))\nprint('Number of files in validation positive set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/valid/pos'))))\nprint('Number of files in validation negative set is {}'.format(len(os.listdir('/kaggle/working/aclImdb/valid/neg'))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:23:56.716097Z","iopub.execute_input":"2025-04-19T11:23:56.716926Z","iopub.status.idle":"2025-04-19T11:23:56.854142Z","shell.execute_reply.started":"2025-04-19T11:23:56.716895Z","shell.execute_reply":"2025-04-19T11:23:56.853463Z"}},"outputs":[{"name":"stdout","text":"Number of files in training positive set is 10000\nNumber of files in training negative set is 10000\nNumber of files in validation positive set is 2500\nNumber of files in validation negative set is 2500\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from tensorflow import keras\n\ntrain_dataset = keras.utils.text_dataset_from_directory(training_set_dir, batch_size=32)\nvalid_dataset = keras.utils.text_dataset_from_directory(validation_set_dir, batch_size=32)\ntest_dataset = keras.utils.text_dataset_from_directory(test_set_dir, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:24:19.999894Z","iopub.execute_input":"2025-04-19T11:24:20.000180Z","iopub.status.idle":"2025-04-19T11:24:37.565115Z","shell.execute_reply.started":"2025-04-19T11:24:20.000158Z","shell.execute_reply":"2025-04-19T11:24:37.564336Z"}},"outputs":[{"name":"stderr","text":"2025-04-19 11:24:21.810846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745061862.012161      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745061862.068292      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 20000 files belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1745061875.119441      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1745061875.120131      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Found 5000 files belonging to 2 classes.\nFound 25000 files belonging to 2 classes.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ntext_vectorization = layers.TextVectorization(max_tokens = 20000, output_mode = 'int', output_sequence_length=600)\ntext_only_train_ds = train_dataset.map(lambda x, y: x)\n\ntext_vectorization.adapt(text_only_train_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:40:54.812995Z","iopub.execute_input":"2025-04-19T11:40:54.813606Z","iopub.status.idle":"2025-04-19T11:41:00.123129Z","shell.execute_reply.started":"2025-04-19T11:40:54.813564Z","shell.execute_reply":"2025-04-19T11:41:00.122512Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"preprocessed_train_dataset = train_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\npreprocessed_valid_dataset = valid_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\npreprocessed_test_dataset = test_dataset.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:41:03.591237Z","iopub.execute_input":"2025-04-19T11:41:03.591764Z","iopub.status.idle":"2025-04-19T11:41:03.902399Z","shell.execute_reply.started":"2025-04-19T11:41:03.591737Z","shell.execute_reply":"2025-04-19T11:41:03.901874Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nclass PositionalEmbedding(keras.layers.Layer):\n    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n        super().__init__(**kwargs)\n        self.token_embeddings = keras.layers.Embedding(input_dim, output_dim)\n        self.position_embeddings = keras.layers.Embedding(sequence_length, output_dim)\n    \n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions  \n\n    def compute_mask(self, inputs, mask=None):\n        return keras.layers.Lambda(lambda x: tf.math.not_equal(x, 0))(inputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:00:34.703243Z","iopub.execute_input":"2025-04-19T12:00:34.703828Z","iopub.status.idle":"2025-04-19T12:00:34.709251Z","shell.execute_reply.started":"2025-04-19T12:00:34.703806Z","shell.execute_reply":"2025-04-19T12:00:34.708488Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from tensorflow import keras\n\nclass TransformerEncoder(keras.layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention_layer = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.dense_proj = keras.Sequential([\n            keras.layers.Dense(dense_dim, activation=\"relu\"),\n            keras.layers.Dense(embed_dim)\n        ])\n        self.layernorm_1 = keras.layers.LayerNormalization()\n        self.layernorm_2 = keras.layers.LayerNormalization()\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            mask = mask[:, tf.newaxis, :]\n        attention_output = self.attention_layer(inputs, inputs, attention_mask=mask)\n        dense_proj_input = self.layernorm_1(attention_output + inputs)\n        proj_output = self.dense_proj(dense_proj_input)\n        return self.layernorm_2(dense_proj_input + proj_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:35:00.039694Z","iopub.execute_input":"2025-04-19T11:35:00.040450Z","iopub.status.idle":"2025-04-19T11:35:00.046431Z","shell.execute_reply.started":"2025-04-19T11:35:00.040425Z","shell.execute_reply":"2025-04-19T11:35:00.045894Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"inputs = keras.layers.Input(shape=(None, ), dtype='int64')\n# embeddings = keras.layers.Embedding(20000, 256)(inputs)\nembeddings = PositionalEmbedding(600, 20000, 256)(inputs)\nx = TransformerEncoder(256, 32, 2)(embeddings)\nx = keras.layers.GlobalMaxPooling1D()(x)\nx = keras.layers.Dropout(0.5)(x)\noutputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\nmodel = keras.Model(inputs, outputs)\nmodel.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:00:38.377715Z","iopub.execute_input":"2025-04-19T12:00:38.378179Z","iopub.status.idle":"2025-04-19T12:00:38.688952Z","shell.execute_reply.started":"2025-04-19T12:00:38.378157Z","shell.execute_reply":"2025-04-19T12:00:38.688389Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'transformer_encoder_1' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ positional_embedding_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m5,273,600\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ transformer_encoder_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m543,776\u001b[0m │ positional_embedding_… │\n│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ transformer_encoder_1… │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m257\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ positional_embedding_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,273,600</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ transformer_encoder_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">543,776</span> │ positional_embedding_… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_encoder_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,817,633\u001b[0m (22.19 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,817,633</span> (22.19 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,817,633\u001b[0m (22.19 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,817,633</span> (22.19 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"model.fit(preprocessed_train_dataset, validation_data=preprocessed_valid_dataset, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:00:57.121550Z","iopub.execute_input":"2025-04-19T12:00:57.121854Z","iopub.status.idle":"2025-04-19T12:08:15.758100Z","shell.execute_reply.started":"2025-04-19T12:00:57.121834Z","shell.execute_reply":"2025-04-19T12:08:15.757343Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 59ms/step - accuracy: 0.6415 - loss: 0.7347 - val_accuracy: 0.7820 - val_loss: 0.4628\nEpoch 2/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 67ms/step - accuracy: 0.8483 - loss: 0.3485 - val_accuracy: 0.8508 - val_loss: 0.3420\nEpoch 3/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step - accuracy: 0.8854 - loss: 0.2757 - val_accuracy: 0.8454 - val_loss: 0.3935\nEpoch 4/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 71ms/step - accuracy: 0.9095 - loss: 0.2292 - val_accuracy: 0.8814 - val_loss: 0.3271\nEpoch 5/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step - accuracy: 0.9258 - loss: 0.1916 - val_accuracy: 0.8860 - val_loss: 0.3656\nEpoch 6/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 75ms/step - accuracy: 0.9416 - loss: 0.1560 - val_accuracy: 0.8802 - val_loss: 0.3296\nEpoch 7/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 73ms/step - accuracy: 0.9532 - loss: 0.1222 - val_accuracy: 0.8814 - val_loss: 0.4122\nEpoch 8/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step - accuracy: 0.9660 - loss: 0.0896 - val_accuracy: 0.8780 - val_loss: 0.4526\nEpoch 9/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 67ms/step - accuracy: 0.9759 - loss: 0.0660 - val_accuracy: 0.8774 - val_loss: 0.6125\nEpoch 10/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 65ms/step - accuracy: 0.9811 - loss: 0.0532 - val_accuracy: 0.8296 - val_loss: 0.5999\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b68cc64cb10>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(f\"Test acc: {model.evaluate(preprocessed_test_dataset)[1]:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:08:59.059377Z","iopub.execute_input":"2025-04-19T12:08:59.059973Z","iopub.status.idle":"2025-04-19T12:09:11.812160Z","shell.execute_reply.started":"2025-04-19T12:08:59.059947Z","shell.execute_reply":"2025-04-19T12:09:11.811572Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.8267 - loss: 0.6209\nTest acc: 0.827\n","output_type":"stream"}],"execution_count":18}]}