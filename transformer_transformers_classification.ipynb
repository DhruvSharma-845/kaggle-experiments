{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:13:34.675469Z","iopub.execute_input":"2025-10-24T18:13:34.675672Z","iopub.status.idle":"2025-10-24T18:13:35.013790Z","shell.execute_reply.started":"2025-10-24T18:13:34.675655Z","shell.execute_reply":"2025-10-24T18:13:35.010718Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -U transformers evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:13:35.015234Z","iopub.execute_input":"2025-10-24T18:13:35.018692Z","iopub.status.idle":"2025-10-24T18:13:38.992573Z","shell.execute_reply.started":"2025-10-24T18:13:35.018667Z","shell.execute_reply":"2025-10-24T18:13:38.991824Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.57.1)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.1.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\n\ntorch.backends.cudnn.deterministic = True\n\nRANDOM_SEED = 123\ntorch.manual_seed(RANDOM_SEED)\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:13:38.993509Z","iopub.execute_input":"2025-10-24T18:13:38.993718Z","iopub.status.idle":"2025-10-24T18:13:40.728678Z","shell.execute_reply.started":"2025-10-24T18:13:38.993697Z","shell.execute_reply":"2025-10-24T18:13:40.727799Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import requests\nimport shutil\nimport gzip\nimport pandas as pd\n\nurl = (\"https://github.com/rasbt/machine-learning-book/raw/main/ch08/movie_data.csv.gz\")\nfilename = url.split(\"/\")[-1]\nwith open(filename, \"wb\") as f:\n    r = requests.get(url)\n    f.write(r.content)\nwith gzip.open('movie_data.csv.gz', 'rb') as f_in:\n    with open('movie_data.csv', 'wb') as f_out:\n        shutil.copyfileobj(f_in, f_out)\n\ndf = pd.read_csv('movie_data.csv')\nprint(df.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:14:08.885879Z","iopub.execute_input":"2025-10-24T18:14:08.886398Z","iopub.status.idle":"2025-10-24T18:14:11.125473Z","shell.execute_reply.started":"2025-10-24T18:14:08.886373Z","shell.execute_reply":"2025-10-24T18:14:11.124806Z"}},"outputs":[{"name":"stdout","text":"                                              review  sentiment\n0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n1  OK... so... I really like Kris Kristofferson a...          0\n2  ***SPOILER*** Do not read this, if you think a...          0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_texts = df.iloc[:35000]['review'].values\ntrain_labels = df.iloc[:35000]['sentiment'].values\nvalid_texts = df.iloc[35000:40000]['review'].values\nvalid_labels = df.iloc[35000:40000]['sentiment'].values\ntest_texts = df.iloc[40000:]['review'].values\ntest_labels = df.iloc[40000:]['sentiment'].values\nprint(train_texts.shape)\nprint(train_labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:14:18.391537Z","iopub.execute_input":"2025-10-24T18:14:18.392288Z","iopub.status.idle":"2025-10-24T18:14:18.398166Z","shell.execute_reply.started":"2025-10-24T18:14:18.392266Z","shell.execute_reply":"2025-10-24T18:14:18.397280Z"}},"outputs":[{"name":"stdout","text":"(35000,)\n(35000,)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import tokenizers\nprint(tokenizers.__version__)\nimport transformers\nprint(transformers.__version__)\n\n\nfrom transformers import AutoTokenizer\nfrom transformers import DistilBertForSequenceClassification\n\n\nMODEL = f\"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:13:40.776559Z","iopub.execute_input":"2025-10-24T18:13:40.777069Z","iopub.status.idle":"2025-10-24T18:13:48.549994Z","shell.execute_reply.started":"2025-10-24T18:13:40.777044Z","shell.execute_reply":"2025-10-24T18:13:48.549164Z"}},"outputs":[{"name":"stdout","text":"0.22.1\n4.57.1\n","output_type":"stream"},{"name":"stderr","text":"2025-10-24 18:13:44.522776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761329624.544907     225 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761329624.551952     225 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\nvalid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True)\n# test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:14:45.316203Z","iopub.execute_input":"2025-10-24T18:14:45.316630Z","iopub.status.idle":"2025-10-24T18:15:01.348259Z","shell.execute_reply.started":"2025-10-24T18:14:45.316607Z","shell.execute_reply":"2025-10-24T18:15:01.347669Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print({key: torch.tensor(val[0]) for key, val in train_encodings.items()})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:21:49.679479Z","iopub.execute_input":"2025-10-24T18:21:49.680189Z","iopub.status.idle":"2025-10-24T18:21:49.696243Z","shell.execute_reply.started":"2025-10-24T18:21:49.680164Z","shell.execute_reply":"2025-10-24T18:21:49.695475Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([  101,  1999,  3326,  1010,  1996, 10563,  9246,  9587, 20959,  1006,\n         8538,  4519,  1007,  5829,  2000,  1996,  2152,  1011,  2465,  2181,\n         1997,  9852,  4033,  1010, 13861,  1010,  6117,  1012,  2006,  1996,\n        25166,  2305,  1010,  6574,  1997, 14414,  1010,  2016,  2001,  7129,\n         1999,  1996, 16125,  1997,  2014,  2160,  1998,  2014,  4028,  2815,\n         4895, 19454,  7178,  1012,  3174,  1011,  2048,  2086,  2101,  1010,\n         1996,  3213,  2928, 11865,  8093,  2386,  1006,  5696, 11463, 10698,\n         1007,  1010,  2040,  2003,  1037,  2280,  2474,  6317,  2008,  2038,\n         5357,  1999, 29591,  2005,  2566,  9103,  2854,  1999,  1051,  1012,\n         1046,  1012,  9304,  3979,  1998,  2333,  2000,  9795,  1010,  7288,\n         2000,  8556,  1996,  2553,  2007,  2010,  4256,  4459,  3134,  1006,\n         4080,  6395,  1007,  2007,  1996,  3800,  1997,  3015,  1037,  2338,\n         1012,  1996, 10575,  5490, 10179, 10867,  1998,  2079,  2025,  6160,\n         2068,  1010,  2021,  2007,  1996,  2490,  1997,  1996,  3394,  6317,\n         3889, 10767,  1006,  2728, 21316,  1007,  2008,  2001,  1999,  3715,\n         1997,  1996,  4812,  1999,  1996,  3963,  1005,  1055,  1010,  2027,\n         7523,  1996,  4735,  1998,  1037,  5658,  1997,  2373,  1998,  2769,\n         2000,  3104,  1996,  4028,  1012,  1026,  7987,  1013,  1028,  1026,\n         7987,  1013,  1028,  1000,  4028,  1999, 13861,  1000,  2003,  1037,\n         2204,  2694,  3185,  1010,  2007,  1996,  2995,  2466,  1997,  1037,\n         4028,  1997,  1037,  5417,  2086,  2214,  2611,  2008,  2001,  5462,\n         2011,  1037,  7272, 10563,  3005,  2388,  2001,  1037,  5817,  1012,\n         1996,  3928,  1998,  4138,  2155,  2109,  2037,  3747,  2000,  3104,\n         1996,  4028,  2005,  2062,  2084,  3174,  2086,  1012,  2174,  1010,\n         1037, 29044,  2100,  6317,  1998,  7979,  2566, 25243,  2099,  1999,\n        29591,  2001,  2583,  2000, 26056,  2129,  1996, 22293,  4126,  2001,\n         5462,  1012,  1996,  9000,  3065,  1996,  4812,  1997,  2928,  1998,\n         1996,  2197,  2420,  1997,  9246,  1999,  5903,  1010,  2021,  2045,\n         2003,  1037,  3768,  1997,  1996,  7603,  1999,  1996,  3689,  3775,\n         9276,  1012,  2026,  3789,  2003,  2698,  1012,  1026,  7987,  1013,\n         1028,  1026,  7987,  1013,  1028,  2516,  1006,  4380,  1007,  1024,\n         2025,  2800,   102,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])}\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"class IMDbDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx], device=DEVICE) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], device=DEVICE)\n        return item\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = IMDbDataset(train_encodings, train_labels)\nvalid_dataset = IMDbDataset(valid_encodings, valid_labels)\n# test_dataset = IMDbDataset(test_encodings, test_labels)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True) \nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False) \n# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:23:39.526298Z","iopub.execute_input":"2025-10-24T18:23:39.527221Z","iopub.status.idle":"2025-10-24T18:23:39.533308Z","shell.execute_reply.started":"2025-10-24T18:23:39.527196Z","shell.execute_reply":"2025-10-24T18:23:39.532475Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\nmodel.to(DEVICE)\nmodel.train()\noptim = torch.optim.Adam(model.parameters(), lr=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:22:11.519603Z","iopub.execute_input":"2025-10-24T18:22:11.519930Z","iopub.status.idle":"2025-10-24T18:22:12.295520Z","shell.execute_reply.started":"2025-10-24T18:22:11.519901Z","shell.execute_reply":"2025-10-24T18:22:12.294707Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import evaluate\nimport numpy as np\nmetric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:22:22.048000Z","iopub.execute_input":"2025-10-24T18:22:22.048763Z","iopub.status.idle":"2025-10-24T18:22:23.550842Z","shell.execute_reply.started":"2025-10-24T18:22:22.048736Z","shell.execute_reply":"2025-10-24T18:22:23.550255Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir='./results', num_train_epochs=3, \n    per_device_train_batch_size=16, per_device_eval_batch_size=16, \n    logging_dir='./logs', logging_steps=10\n)\ntrainer = Trainer(\n    model=model, args=training_args, \n    train_dataset=train_dataset, eval_dataset=valid_dataset, \n    optimizers=(optim, None), compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T18:23:49.489797Z","iopub.execute_input":"2025-10-24T18:23:49.490295Z","iopub.status.idle":"2025-10-24T18:23:52.764563Z","shell.execute_reply.started":"2025-10-24T18:23:49.490273Z","shell.execute_reply":"2025-10-24T18:23:52.763943Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}