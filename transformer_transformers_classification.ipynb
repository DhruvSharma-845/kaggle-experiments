{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:14:06.412955Z","iopub.execute_input":"2025-10-30T18:14:06.413228Z","iopub.status.idle":"2025-10-30T18:14:06.737724Z","shell.execute_reply.started":"2025-10-30T18:14:06.413210Z","shell.execute_reply":"2025-10-30T18:14:06.736897Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -U transformers==4.37.0 evaluate accelerate==0.26.0 peft==0.6.0 trl==0.7.4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:14:06.738537Z","iopub.execute_input":"2025-10-30T18:14:06.738935Z","iopub.status.idle":"2025-10-30T18:14:10.644632Z","shell.execute_reply.started":"2025-10-30T18:14:06.738909Z","shell.execute_reply":"2025-10-30T18:14:10.643896Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers==4.37.0 in /usr/local/lib/python3.11/dist-packages (4.37.0)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.6)\nRequirement already satisfied: accelerate==0.26.0 in /usr/local/lib/python3.11/dist-packages (0.26.0)\nRequirement already satisfied: peft==0.6.0 in /usr/local/lib/python3.11/dist-packages (0.6.0)\nRequirement already satisfied: trl==0.7.4 in /usr/local/lib/python3.11/dist-packages (0.7.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (3.19.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (2.32.5)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (7.1.0)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (2.6.0+cu124)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from trl==0.7.4) (4.1.1)\nRequirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.11/dist-packages (from trl==0.7.4) (0.9.35)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.7.4) (22.0.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.37.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.37.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.37.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.37.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.37.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.37.0) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (2025.8.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.26.0) (1.3.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.7.4) (0.17.0)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.7.4) (14.1.0)\nRequirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.7.4) (1.7.2)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.7.4) (4.4.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (2.19.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.26.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.37.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.37.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.37.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.37.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.37.0) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (0.1.2)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\n\ntorch.backends.cudnn.deterministic = True\n\nRANDOM_SEED = 123\ntorch.manual_seed(RANDOM_SEED)\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:14:10.645570Z","iopub.execute_input":"2025-10-30T18:14:10.645813Z","iopub.status.idle":"2025-10-30T18:14:12.353068Z","shell.execute_reply.started":"2025-10-30T18:14:10.645792Z","shell.execute_reply":"2025-10-30T18:14:12.352399Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import requests\nimport shutil\nimport gzip\nimport pandas as pd\n\nurl = (\"https://github.com/rasbt/machine-learning-book/raw/main/ch08/movie_data.csv.gz\")\nfilename = url.split(\"/\")[-1]\nwith open(filename, \"wb\") as f:\n    r = requests.get(url)\n    f.write(r.content)\nwith gzip.open('movie_data.csv.gz', 'rb') as f_in:\n    with open('movie_data.csv', 'wb') as f_out:\n        shutil.copyfileobj(f_in, f_out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:14:12.354703Z","iopub.execute_input":"2025-10-30T18:14:12.355024Z","iopub.status.idle":"2025-10-30T18:14:13.611942Z","shell.execute_reply.started":"2025-10-30T18:14:12.355005Z","shell.execute_reply":"2025-10-30T18:14:13.611099Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from datasets import load_dataset\nmovie_train_ds = load_dataset(\"csv\", data_files=\"movie_data.csv\", sep=\",\", names=[\"review\", \"label\"], skiprows=1, split='train[:70%]')\nmovie_valid_ds = load_dataset(\"csv\", data_files=\"movie_data.csv\", sep=\",\", names=[\"review\", \"label\"], skiprows=1, split='train[70%:85%]')\nmovie_test_ds = load_dataset(\"csv\", data_files=\"movie_data.csv\", sep=\",\", names=[\"review\", \"label\"], skiprows=1, split='train[85%:]')\n\nprint(movie_train_ds)\nprint(movie_valid_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:27:19.235019Z","iopub.execute_input":"2025-10-30T18:27:19.235331Z","iopub.status.idle":"2025-10-30T18:27:20.376074Z","shell.execute_reply.started":"2025-10-30T18:27:19.235311Z","shell.execute_reply":"2025-10-30T18:27:20.375309Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"192f69b59e644bd4aa86d667d0c3af6a"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['review', 'label'],\n    num_rows: 35000\n})\nDataset({\n    features: ['review', 'label'],\n    num_rows: 7500\n})\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"movie_train_ds['label'][:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:27:31.609555Z","iopub.execute_input":"2025-10-30T18:27:31.609852Z","iopub.status.idle":"2025-10-30T18:27:31.615383Z","shell.execute_reply.started":"2025-10-30T18:27:31.609832Z","shell.execute_reply":"2025-10-30T18:27:31.614769Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[1, 0]"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# train_texts = df.iloc[:35000]['review'].values\n# train_labels = df.iloc[:35000]['sentiment'].values\n# valid_texts = df.iloc[35000:40000]['review'].values\n# valid_labels = df.iloc[35000:40000]['sentiment'].values\n# test_texts = df.iloc[40000:]['review'].values\n# test_labels = df.iloc[40000:]['sentiment'].values\n# print(train_texts.shape)\n# print(train_labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:14:15.304687Z","iopub.execute_input":"2025-10-30T18:14:15.305008Z","iopub.status.idle":"2025-10-30T18:14:15.316099Z","shell.execute_reply.started":"2025-10-30T18:14:15.304989Z","shell.execute_reply":"2025-10-30T18:14:15.315226Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import tokenizers\nprint(tokenizers.__version__)\nimport transformers\nprint(transformers.__version__)\n\n\nfrom transformers import AutoTokenizer\n\nMODEL = f\"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=False, use_auth_token=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:27:34.943007Z","iopub.execute_input":"2025-10-30T18:27:34.943277Z","iopub.status.idle":"2025-10-30T18:27:35.066382Z","shell.execute_reply.started":"2025-10-30T18:27:34.943257Z","shell.execute_reply":"2025-10-30T18:27:35.065463Z"}},"outputs":[{"name":"stdout","text":"0.15.2\n4.37.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py:711: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"review\"], padding=True, truncation=True)\n\nmovie_train_tokenized = movie_train_ds.map(tokenize, batched=True, batch_size=None)\nmovie_valid_tokenized = movie_valid_ds.map(tokenize, batched=True, batch_size=None)\nmovie_test_tokenized = movie_test_ds.map(tokenize, batched=True, batch_size=None)\n\nprint(movie_train_tokenized)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:27:40.366731Z","iopub.execute_input":"2025-10-30T18:27:40.367012Z","iopub.status.idle":"2025-10-30T18:28:08.990827Z","shell.execute_reply.started":"2025-10-30T18:27:40.366995Z","shell.execute_reply":"2025-10-30T18:28:08.990041Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/35000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93e4c1798fa4546a61ee1c8bc0df4e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68a768450c3d4049a784e87d28ebff6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6ff87ee5bfb42689120abe0a9d76be5"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['review', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 35000\n})\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# class IMDbDataset(torch.utils.data.Dataset):\n#     def __init__(self, encodings, labels):\n#         self.encodings = encodings\n#         self.labels = labels\n#     def __getitem__(self, idx):\n#         item = {key: torch.tensor(val[idx], device=DEVICE) for key, val in self.encodings.items()}\n#         item['labels'] = torch.tensor(self.labels[idx], device=DEVICE)\n#         return item\n#     def __len__(self):\n#         return len(self.labels)\n\n# train_dataset = IMDbDataset(train_encodings, train_labels)\n# valid_dataset = IMDbDataset(valid_encodings, valid_labels)\n# # test_dataset = IMDbDataset(test_encodings, test_labels)\n# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True) \n# valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False) \n# # test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:14:45.654995Z","iopub.execute_input":"2025-10-30T18:14:45.655225Z","iopub.status.idle":"2025-10-30T18:14:45.659112Z","shell.execute_reply.started":"2025-10-30T18:14:45.655202Z","shell.execute_reply":"2025-10-30T18:14:45.658342Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=2).to(DEVICE)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:28:14.775850Z","iopub.execute_input":"2025-10-30T18:28:14.776367Z","iopub.status.idle":"2025-10-30T18:28:15.064909Z","shell.execute_reply.started":"2025-10-30T18:28:14.776345Z","shell.execute_reply":"2025-10-30T18:28:15.064161Z"}},"outputs":[{"name":"stdout","text":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import evaluate\nimport numpy as np\nmetric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    # logits, labels = eval_pred\n    # predictions = np.argmax(logits, axis=-1)\n    labels = eval_pred.label_ids\n    preds = eval_pred.predictions.argmax(-1)\n    return metric.compute(predictions=preds, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:28:22.912387Z","iopub.execute_input":"2025-10-30T18:28:22.913119Z","iopub.status.idle":"2025-10-30T18:28:23.554001Z","shell.execute_reply.started":"2025-10-30T18:28:22.913094Z","shell.execute_reply":"2025-10-30T18:28:23.553415Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(movie_train_tokenized[:3].items())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:28:27.365128Z","iopub.execute_input":"2025-10-30T18:28:27.365724Z","iopub.status.idle":"2025-10-30T18:28:27.372297Z","shell.execute_reply.started":"2025-10-30T18:28:27.365698Z","shell.execute_reply":"2025-10-30T18:28:27.371547Z"}},"outputs":[{"name":"stdout","text":"dict_items([('review', ['In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available', \"OK... so... I really like Kris Kristofferson and his usual easy going delivery of lines in his movies. Age has helped him with his soft spoken low energy style and he will steal a scene effortlessly. But, Disappearance is his misstep. Holy Moly, this was a bad movie! <br /><br />I must give kudos to the cinematography and and the actors, including Kris, for trying their darndest to make sense from this goofy, confusing story! None of it made sense and Kris probably didn't understand it either and he was just going through the motions hoping someone would come up to him and tell him what it was all about! <br /><br />I don't care that everyone on this movie was doing out of love for the project, or some such nonsense... I've seen low budget movies that had a plot for goodness sake! This had none, zilcho, nada, zippo, empty of reason... a complete waste of good talent, scenery and celluloid! <br /><br />I rented this piece of garbage for a buck, and I want my money back! I want my 2 hours back I invested on this Grade F waste of my time! Don't watch this movie, or waste 1 minute of your valuable time while passing through a room where it's playing or even open up the case that is holding the DVD! Believe me, you'll thank me for the advice!\", '***SPOILER*** Do not read this, if you think about watching that movie, although it would be a waste of time. (By the way: The plot is so predictable that it does not make any difference if you read this or not anyway)<br /><br />If you are wondering whether to see \"Coyote Ugly\" or not: don\\'t! It\\'s not worth either the money for the ticket or the VHS / DVD. A typical \"Chick-Feel-Good-Flick\", one could say. The plot itself is as shallow as it can be, a ridiculous and uncritical version of the American Dream. The young good-looking girl from a small town becoming a big success in New York. The few desperate attempts of giving the movie any depth fail, such as the \"tragic\" accident of the father, the \"difficulties\" of Violet\\'s relationship with her boyfriend, and so on. McNally (Director) tries to arouse the audience\\'s pity and sadness put does not have any chance to succeed in this attempt due to the bad script and the shallow acting. Especially Piper Perabo completely fails in convincing one of \"Jersey\\'s\" fear of singing in front of an audience. The only good (and quite funny thing) about \"Coyote Ugly\" is John Goodman, who represents the small ray of hope of this movie.<br /><br />I was very astonished, that Jerry Bruckheimer produced this movie. First \"Gone In 60 Seconds\" and now this... what happened to great movies like \"The Rock\" and \"Con Air\"? THAT was true Bruckheimer stuff.<br /><br />If you are looking for a superficial movie with good looking women just to have a relaxed evening, you should better go and see \"Charlie\\'s Angels\" (it\\'s much more funny, entertaining and self-ironic) instead of this flick.<br /><br />Two thumbs down (3 out of 10).']), ('label', [1, 0, 0]), ('input_ids', [[101, 1999, 3326, 1010, 1996, 10563, 9246, 9587, 20959, 1006, 8538, 4519, 1007, 5829, 2000, 1996, 2152, 1011, 2465, 2181, 1997, 9852, 4033, 1010, 13861, 1010, 6117, 1012, 2006, 1996, 25166, 2305, 1010, 6574, 1997, 14414, 1010, 2016, 2001, 7129, 1999, 1996, 16125, 1997, 2014, 2160, 1998, 2014, 4028, 2815, 4895, 19454, 7178, 1012, 3174, 1011, 2048, 2086, 2101, 1010, 1996, 3213, 2928, 11865, 8093, 2386, 1006, 5696, 11463, 10698, 1007, 1010, 2040, 2003, 1037, 2280, 2474, 6317, 2008, 2038, 5357, 1999, 29591, 2005, 2566, 9103, 2854, 1999, 1051, 1012, 1046, 1012, 9304, 3979, 1998, 2333, 2000, 9795, 1010, 7288, 2000, 8556, 1996, 2553, 2007, 2010, 4256, 4459, 3134, 1006, 4080, 6395, 1007, 2007, 1996, 3800, 1997, 3015, 1037, 2338, 1012, 1996, 10575, 5490, 10179, 10867, 1998, 2079, 2025, 6160, 2068, 1010, 2021, 2007, 1996, 2490, 1997, 1996, 3394, 6317, 3889, 10767, 1006, 2728, 21316, 1007, 2008, 2001, 1999, 3715, 1997, 1996, 4812, 1999, 1996, 3963, 1005, 1055, 1010, 2027, 7523, 1996, 4735, 1998, 1037, 5658, 1997, 2373, 1998, 2769, 2000, 3104, 1996, 4028, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1000, 4028, 1999, 13861, 1000, 2003, 1037, 2204, 2694, 3185, 1010, 2007, 1996, 2995, 2466, 1997, 1037, 4028, 1997, 1037, 5417, 2086, 2214, 2611, 2008, 2001, 5462, 2011, 1037, 7272, 10563, 3005, 2388, 2001, 1037, 5817, 1012, 1996, 3928, 1998, 4138, 2155, 2109, 2037, 3747, 2000, 3104, 1996, 4028, 2005, 2062, 2084, 3174, 2086, 1012, 2174, 1010, 1037, 29044, 2100, 6317, 1998, 7979, 2566, 25243, 2099, 1999, 29591, 2001, 2583, 2000, 26056, 2129, 1996, 22293, 4126, 2001, 5462, 1012, 1996, 9000, 3065, 1996, 4812, 1997, 2928, 1998, 1996, 2197, 2420, 1997, 9246, 1999, 5903, 1010, 2021, 2045, 2003, 1037, 3768, 1997, 1996, 7603, 1999, 1996, 3689, 3775, 9276, 1012, 2026, 3789, 2003, 2698, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2516, 1006, 4380, 1007, 1024, 2025, 2800, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 7929, 1012, 1012, 1012, 2061, 1012, 1012, 1012, 1045, 2428, 2066, 19031, 19031, 3406, 12494, 3385, 1998, 2010, 5156, 3733, 2183, 6959, 1997, 3210, 1999, 2010, 5691, 1012, 2287, 2038, 3271, 2032, 2007, 2010, 3730, 5287, 2659, 2943, 2806, 1998, 2002, 2097, 8954, 1037, 3496, 29483, 1012, 2021, 1010, 13406, 2003, 2010, 3335, 2618, 2361, 1012, 4151, 9587, 2135, 1010, 2023, 2001, 1037, 2919, 3185, 999, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2442, 2507, 13970, 12269, 2000, 1996, 16434, 1998, 1998, 1996, 5889, 1010, 2164, 19031, 1010, 2005, 2667, 2037, 18243, 13629, 3367, 2000, 2191, 3168, 2013, 2023, 27243, 1010, 16801, 2466, 999, 3904, 1997, 2009, 2081, 3168, 1998, 19031, 2763, 2134, 1005, 1056, 3305, 2009, 2593, 1998, 2002, 2001, 2074, 2183, 2083, 1996, 15323, 5327, 2619, 2052, 2272, 2039, 2000, 2032, 1998, 2425, 2032, 2054, 2009, 2001, 2035, 2055, 999, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2123, 1005, 1056, 2729, 2008, 3071, 2006, 2023, 3185, 2001, 2725, 2041, 1997, 2293, 2005, 1996, 2622, 1010, 2030, 2070, 2107, 14652, 1012, 1012, 1012, 1045, 1005, 2310, 2464, 2659, 5166, 5691, 2008, 2018, 1037, 5436, 2005, 15003, 8739, 999, 2023, 2018, 3904, 1010, 1062, 4014, 9905, 1010, 23233, 2050, 1010, 14101, 6873, 1010, 4064, 1997, 3114, 1012, 1012, 1012, 1037, 3143, 5949, 1997, 2204, 5848, 1010, 17363, 1998, 3526, 18845, 3593, 999, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 12524, 2023, 3538, 1997, 13044, 2005, 1037, 10131, 1010, 1998, 1045, 2215, 2026, 2769, 2067, 999, 1045, 2215, 2026, 1016, 2847, 2067, 1045, 11241, 2006, 2023, 3694, 1042, 5949, 1997, 2026, 2051, 999, 2123, 1005, 1056, 3422, 2023, 3185, 1010, 2030, 5949, 1015, 3371, 1997, 2115, 7070, 2051, 2096, 4458, 2083, 1037, 2282, 2073, 2009, 1005, 1055, 2652, 2030, 2130, 2330, 2039, 1996, 2553, 2008, 2003, 3173, 1996, 4966, 999, 2903, 2033, 1010, 2017, 1005, 2222, 4067, 2033, 2005, 1996, 6040, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1008, 1008, 1008, 27594, 2121, 1008, 1008, 1008, 2079, 2025, 3191, 2023, 1010, 2065, 2017, 2228, 2055, 3666, 2008, 3185, 1010, 2348, 2009, 2052, 2022, 1037, 5949, 1997, 2051, 1012, 1006, 2011, 1996, 2126, 1024, 1996, 5436, 2003, 2061, 21425, 2008, 2009, 2515, 2025, 2191, 2151, 4489, 2065, 2017, 3191, 2023, 2030, 2025, 4312, 1007, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2065, 2017, 2024, 6603, 3251, 2000, 2156, 1000, 20457, 9200, 1000, 2030, 2025, 1024, 2123, 1005, 1056, 999, 2009, 1005, 1055, 2025, 4276, 2593, 1996, 2769, 2005, 1996, 7281, 2030, 1996, 17550, 1013, 4966, 1012, 1037, 5171, 1000, 14556, 1011, 2514, 1011, 2204, 1011, 17312, 1000, 1010, 2028, 2071, 2360, 1012, 1996, 5436, 2993, 2003, 2004, 8467, 2004, 2009, 2064, 2022, 1010, 1037, 9951, 1998, 4895, 26775, 26116, 2544, 1997, 1996, 2137, 3959, 1012, 1996, 2402, 2204, 1011, 2559, 2611, 2013, 1037, 2235, 2237, 3352, 1037, 2502, 3112, 1999, 2047, 2259, 1012, 1996, 2261, 7143, 4740, 1997, 3228, 1996, 3185, 2151, 5995, 8246, 1010, 2107, 2004, 1996, 1000, 13800, 1000, 4926, 1997, 1996, 2269, 1010, 1996, 1000, 8190, 1000, 1997, 8766, 1005, 1055, 3276, 2007, 2014, 6898, 1010, 1998, 2061, 2006, 1012, 11338, 26827, 1006, 2472, 1007, 5363, 2000, 12098, 15441, 1996, 4378, 1005, 1055, 12063, 1998, 12039, 2404, 2515, 2025, 2031, 2151, 3382, 2000, 9510, 1999, 2023, 3535, 2349, 2000, 1996, 2919, 5896, 1998, 1996, 8467, 3772, 1012, 2926, 11939, 2566, 7875, 2080, 3294, 11896, 1999, 13359, 2028, 1997, 1000, 3933, 1005, 1055, 1000, 3571, 1997, 4823, 1999, 2392, 1997, 2019, 4378, 1012, 1996, 2069, 2204, 1006, 1998, 3243, 6057, 2518, 1007, 2055, 1000, 20457, 9200, 1000, 2003, 2198, 14514, 1010, 2040, 5836, 1996, 2235, 4097, 1997, 3246, 1997, 2023, 3185, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2001, 2200, 22741, 1010, 2008, 6128, 7987, 12722, 18826, 2550, 2023, 3185, 1012, 2034, 1000, 2908, 1999, 3438, 3823, 1000, 1998, 2085, 2023, 1012, 1012, 1012, 2054, 3047, 2000, 2307, 5691, 2066, 1000, 1996, 2600, 1000, 1998, 1000, 9530, 2250, 1000, 1029, 2008, 2001, 2995, 7987, 12722, 18826, 4933, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2065, 2017, 2024, 2559, 2005, 1037, 23105, 3185, 2007, 2204, 2559, 2308, 2074, 2000, 2031, 1037, 8363, 3944, 1010, 2017, 2323, 2488, 2175, 1998, 2156, 1000, 4918, 1005, 1055, 7048, 1000, 1006, 2009, 1005, 1055, 2172, 2062, 6057, 1010, 14036, 1998, 2969, 1011, 19313, 1007, 2612, 1997, 2023, 17312, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2048, 16784, 2091, 1006, 1017, 2041, 1997, 2184, 1007, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), ('attention_mask', [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])])\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"movie_train_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nmovie_valid_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:32:13.332642Z","iopub.execute_input":"2025-10-30T18:32:13.333334Z","iopub.status.idle":"2025-10-30T18:32:13.337968Z","shell.execute_reply.started":"2025-10-30T18:32:13.333308Z","shell.execute_reply":"2025-10-30T18:32:13.337231Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nbatch_size = 16\nlogging_steps = len(movie_train_tokenized) // batch_size\nmodel_name = f\"{MODEL}-finetuned-movie-sentiment\"\ntraining_args = TrainingArguments(output_dir=model_name, num_train_epochs=3, learning_rate=2e-5,\n                                  per_device_train_batch_size=batch_size,\n                                  per_device_eval_batch_size=batch_size,\n                                  weight_decay=0.01,\n                                  evaluation_strategy=\"epoch\",\n                                  logging_steps=logging_steps,\n                                  log_level=\"error\", report_to=\"none\")\n\ntrainer = Trainer(\n    model=model, args=training_args, \n    train_dataset=movie_train_tokenized, eval_dataset=movie_valid_tokenized, \n    tokenizer=tokenizer, compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:33:05.386538Z","iopub.execute_input":"2025-10-30T18:33:05.387164Z","iopub.status.idle":"2025-10-30T18:33:05.397001Z","shell.execute_reply.started":"2025-10-30T18:33:05.387142Z","shell.execute_reply":"2025-10-30T18:33:05.396362Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:33:09.701906Z","iopub.execute_input":"2025-10-30T18:33:09.702177Z","iopub.status.idle":"2025-10-30T18:45:40.191519Z","shell.execute_reply.started":"2025-10-30T18:33:09.702157Z","shell.execute_reply":"2025-10-30T18:45:40.190178Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_303/4032920361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1540\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1872\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 ):\n\u001b[1;32m   1876\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":37},{"cell_type":"code","source":"preds_output = trainer.predict(movie_test_tokenized)\nprint(preds_output.metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T18:45:48.634485Z","iopub.execute_input":"2025-10-30T18:45:48.635119Z","iopub.status.idle":"2025-10-30T18:46:58.906158Z","shell.execute_reply.started":"2025-10-30T18:45:48.635095Z","shell.execute_reply":"2025-10-30T18:46:58.905338Z"}},"outputs":[{"name":"stdout","text":"{'test_loss': 0.20976227521896362, 'test_accuracy': 0.9208, 'test_runtime': 70.2644, 'test_samples_per_second': 106.74, 'test_steps_per_second': 6.675}\n","output_type":"stream"}],"execution_count":38}]}