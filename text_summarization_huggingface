{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:46:19.760197Z","iopub.execute_input":"2025-06-21T16:46:19.760877Z","iopub.status.idle":"2025-06-21T16:46:20.052735Z","shell.execute_reply.started":"2025-06-21T16:46:19.760843Z","shell.execute_reply":"2025-06-21T16:46:20.051927Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:47:42.958712Z","iopub.execute_input":"2025-06-21T16:47:42.959016Z","iopub.status.idle":"2025-06-21T16:47:42.974576Z","shell.execute_reply.started":"2025-06-21T16:47:42.958994Z","shell.execute_reply":"2025-06-21T16:47:42.973661Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4de24368524b478f914ae33158764ac9"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:46:20.522210Z","iopub.execute_input":"2025-06-21T16:46:20.522484Z","iopub.status.idle":"2025-06-21T16:46:21.738244Z","shell.execute_reply.started":"2025-06-21T16:46:20.522459Z","shell.execute_reply":"2025-06-21T16:46:21.737643Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"ds_samsum = load_dataset(\"knkarthick/samsum\")\nprint(ds_samsum)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:46:21.740035Z","iopub.execute_input":"2025-06-21T16:46:21.740422Z","iopub.status.idle":"2025-06-21T16:46:25.716666Z","shell.execute_reply.started":"2025-06-21T16:46:21.740404Z","shell.execute_reply":"2025-06-21T16:46:25.716049Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8afb7b589d6473dbbfdd5a3e70b52fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.csv:   0%|          | 0.00/9.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0491b5a1313a458284a0aa028bb306c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.csv:   0%|          | 0.00/504k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"280ed8baa4254e638e49933f2bd8a9fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv:   0%|          | 0.00/522k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b1f3fd4eac84ae49f8eb3a93885476a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cca2a3070f14a52bb64622bf9b62b45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60339b28754f4584841de0446b36916e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9531171bc69e4d1187bbcf7090d7a6b8"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 14732\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 818\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 819\n    })\n})\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:46:25.717437Z","iopub.execute_input":"2025-06-21T16:46:25.717902Z","iopub.status.idle":"2025-06-21T16:46:30.530696Z","shell.execute_reply.started":"2025-06-21T16:46:25.717875Z","shell.execute_reply":"2025-06-21T16:46:30.530118Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_ckpt = \"google/pegasus-cnn_dailymail\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:46:30.531529Z","iopub.execute_input":"2025-06-21T16:46:30.531757Z","iopub.status.idle":"2025-06-21T16:47:11.924102Z","shell.execute_reply.started":"2025-06-21T16:46:30.531738Z","shell.execute_reply":"2025-06-21T16:47:11.923048Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3d6a077f0cd4e81953c33c2e3acaa32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38acbd1c746d471da50454091d686a81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5504716be854f799d0c62ab92e4e081"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0057b3cdc5ea48c495e5edb57caa1fce"}},"metadata":{}},{"name":"stderr","text":"2025-06-21 16:46:43.959140: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750524404.195652      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750524404.267013      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7992a453f6584aa1b58443705f559577"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59e35868bcdd487baad22f48da9115f0"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c41cd41586a34f86b8d60589d02c336d"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def convert_examples_to_features(example_batch):\n    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024, truncation=True)\n\n    with tokenizer.as_target_tokenizer():\n        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128, truncation=True)\n\n    return {\"input_ids\": input_encodings[\"input_ids\"],\n            \"attention_mask\": input_encodings[\"attention_mask\"],\n            \"labels\": target_encodings[\"input_ids\"]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:47:11.925548Z","iopub.execute_input":"2025-06-21T16:47:11.926258Z","iopub.status.idle":"2025-06-21T16:47:11.932114Z","shell.execute_reply.started":"2025-06-21T16:47:11.926223Z","shell.execute_reply":"2025-06-21T16:47:11.931150Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"ds_samsum = ds_samsum.filter(lambda example: example['dialogue'] is not None)\ndataset_samsum_pt = ds_samsum.map(convert_examples_to_features, batched=True)\ncolumns = [\"input_ids\", \"labels\", \"attention_mask\"]\ndataset_samsum_pt.set_format(type=\"torch\", columns=columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:47:11.933091Z","iopub.execute_input":"2025-06-21T16:47:11.933461Z","iopub.status.idle":"2025-06-21T16:47:23.030002Z","shell.execute_reply.started":"2025-06-21T16:47:11.933440Z","shell.execute_reply":"2025-06-21T16:47:23.029303Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d3c02ff3e8c41c5bd2a2550d29c85fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eb08aeda85b424b922b8f8f2b367ef9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5629b6f7a1ef41b1b185cd62a16a4f93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14731 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27f9895d5e55482a9b73a9d30d5c505e"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ef58b5497c4cbf8304991a31a2d01b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d82d410650443fbb48540de1e3df742"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"print(dataset_samsum_pt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:47:23.030959Z","iopub.execute_input":"2025-06-21T16:47:23.031227Z","iopub.status.idle":"2025-06-21T16:47:23.035506Z","shell.execute_reply.started":"2025-06-21T16:47:23.031209Z","shell.execute_reply":"2025-06-21T16:47:23.034958Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 14731\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 818\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 819\n    })\n})\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\nseq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:47:23.037355Z","iopub.execute_input":"2025-06-21T16:47:23.037553Z","iopub.status.idle":"2025-06-21T16:47:25.735172Z","shell.execute_reply.started":"2025-06-21T16:47:23.037538Z","shell.execute_reply":"2025-06-21T16:47:25.734333Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n    weight_decay=0.01, logging_steps=10, push_to_hub=True, \n    eval_strategy=\"epoch\", eval_steps=500, save_steps=1e6,\n    gradient_accumulation_steps=16, log_level=\"debug\", report_to=\"none\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:47:25.735992Z","iopub.execute_input":"2025-06-21T16:47:25.736290Z","iopub.status.idle":"2025-06-21T16:47:28.558325Z","shell.execute_reply.started":"2025-06-21T16:47:25.736266Z","shell.execute_reply":"2025-06-21T16:47:28.557775Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"trainer = Trainer(model=model, args=training_args,\n                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n                  train_dataset=dataset_samsum_pt[\"train\"],\n                  eval_dataset=dataset_samsum_pt[\"validation\"])\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:47:57.175219Z","iopub.execute_input":"2025-06-21T16:47:57.175498Z","iopub.status.idle":"2025-06-21T16:55:58.730841Z","shell.execute_reply.started":"2025-06-21T16:47:57.175477Z","shell.execute_reply":"2025-06-21T16:55:58.729852Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/4284936721.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(model=model, args=training_args,\nCurrently training with a batch size of: 1\nThe following columns in the training set don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: dialogue, id, summary. If dialogue, id, summary are not expected by `PegasusForConditionalGeneration.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 14,731\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 16\n  Total optimization steps = 920\n  Number of trainable parameters = 568,699,904\n/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='228' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [228/920 07:56 < 24:17, 0.47 it/s, Epoch 0.25/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4284936721.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_samsum_pt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   eval_dataset=dataset_samsum_pt[\"validation\"])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2234\u001b[0m                 \u001b[0;31m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m                 return inner_training_loop(\n\u001b[0m\u001b[1;32m   2237\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m                     \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2558\u001b[0m                     )\n\u001b[1;32m   2559\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3780\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3782\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:58:36.834635Z","iopub.execute_input":"2025-06-21T16:58:36.835188Z","iopub.status.idle":"2025-06-21T16:58:42.738363Z","shell.execute_reply.started":"2025-06-21T16:58:36.835164Z","shell.execute_reply":"2025-06-21T16:58:42.737633Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.4 fsspec-2025.3.0\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:59:13.095568Z","iopub.execute_input":"2025-06-21T16:59:13.096217Z","iopub.status.idle":"2025-06-21T16:59:18.106534Z","shell.execute_reply.started":"2025-06-21T16:59:13.096188Z","shell.execute_reply":"2025-06-21T16:59:18.105740Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=69f1ce4d70949409e0f93ec9c6d60f95b642c9297b35d1815e5c47e11bffbc2a\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from evaluate import load\nrouge_metric = load(\"rouge\")\nrouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:59:20.885770Z","iopub.execute_input":"2025-06-21T16:59:20.886045Z","iopub.status.idle":"2025-06-21T16:59:21.495522Z","shell.execute_reply.started":"2025-06-21T16:59:20.886021Z","shell.execute_reply":"2025-06-21T16:59:21.494938Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from tqdm import tqdm \n\ndef chunks(list_of_elements, batch_size):\n    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n    for i in range(0, len(list_of_elements), batch_size):\n        yield list_of_elements[i : i + batch_size]\n\ndef evaluate_summaries_pegasus(dataset, metric, model, tokenizer, batch_size=16, device=device, column_text=\"article\", column_summary=\"highlights\"):\n    input_batches = list(chunks(dataset[column_text], batch_size))\n    target_batches = list(chunks(dataset[column_summary], batch_size))\n\n    for input_batch, target_batch in tqdm(zip(input_batches, target_batches), total=len(input_batches)):\n\n        inputs = tokenizer(input_batch, max_length=1024,  truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n\n        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                         attention_mask=inputs[\"attention_mask\"].to(device), length_penalty=0.8, num_beams=8, max_length=128)\n\n        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in summaries]\n        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n\n    score = metric.compute()\n    return score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T16:59:25.159692Z","iopub.execute_input":"2025-06-21T16:59:25.160436Z","iopub.status.idle":"2025-06-21T16:59:25.167253Z","shell.execute_reply.started":"2025-06-21T16:59:25.160413Z","shell.execute_reply":"2025-06-21T16:59:25.166585Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"score = evaluate_summaries_pegasus(ds_samsum[\"test\"], rouge_metric, trainer.model, tokenizer, batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(score)\npd.DataFrame(score, index=[f\"pegasus\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T17:10:29.578170Z","iopub.execute_input":"2025-06-21T17:10:29.578449Z","iopub.status.idle":"2025-06-21T17:10:29.604992Z","shell.execute_reply.started":"2025-06-21T17:10:29.578429Z","shell.execute_reply":"2025-06-21T17:10:29.604242Z"}},"outputs":[{"name":"stdout","text":"{'rouge1': 0.3853960364724295, 'rouge2': 0.16790847141990428, 'rougeL': 0.30344011879571964, 'rougeLsum': 0.3035335953694651}\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"           rouge1    rouge2   rougeL  rougeLsum\npegasus  0.385396  0.167908  0.30344   0.303534","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pegasus</th>\n      <td>0.385396</td>\n      <td>0.167908</td>\n      <td>0.30344</td>\n      <td>0.303534</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"trainer.push_to_hub(\"Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T17:10:36.968373Z","iopub.execute_input":"2025-06-21T17:10:36.969137Z","iopub.status.idle":"2025-06-21T17:11:41.632786Z","shell.execute_reply.started":"2025-06-21T17:10:36.969104Z","shell.execute_reply":"2025-06-21T17:11:41.632152Z"}},"outputs":[{"name":"stderr","text":"Saving model checkpoint to pegasus-samsum\n/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\nConfiguration saved in pegasus-samsum/config.json\nConfiguration saved in pegasus-samsum/generation_config.json\nModel weights saved in pegasus-samsum/model.safetensors\ntokenizer config file saved in pegasus-samsum/tokenizer_config.json\nSpecial tokens file saved in pegasus-samsum/special_tokens_map.json\nDropping the following result as it does not have all the necessary fields:\n{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06998f3524094a73a2966917f25ecba6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0e3313f1f2746a6be145492ce209780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca7e734976ae41ef99a5355d2d0fc973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da355a997ad84a3b81a164bed6082cb2"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/DhruvSharma-845/pegasus-samsum/commit/571213a45342bfba5546fae6dcf8b4174aafc87f', commit_message='Training complete!', commit_description='', oid='571213a45342bfba5546fae6dcf8b4174aafc87f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/DhruvSharma-845/pegasus-samsum', endpoint='https://huggingface.co', repo_type='model', repo_id='DhruvSharma-845/pegasus-samsum'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":30}]}